{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing\n",
    "\n",
    "This Jupyter Noterbook helps us to convert binary attribute(s) to +/-1, categorical attributes(s) to onehot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the data which were cleaned from the `data cleaning` step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(116, 10)\n",
      "[['48.0' '23.5' '70.0' ... '7.99585' '417.11400000000003' '1.0']\n",
      " ['83.0' '20.69049454' '92.0' ... '4.06405' '468.786' '1.0']\n",
      " ['82.0' '23.12467037' '91.0' ... '9.27715' '554.697' '1.0']\n",
      " ...\n",
      " ['65.0' '32.05' '97.0' ... '10.33' '314.05' '2.0']\n",
      " ['72.0' '25.59' '82.0' ... '3.27' '392.46' '2.0']\n",
      " ['86.0' '27.18' '138.0' ... '4.35' '90.09' '2.0']]\n"
     ]
    }
   ],
   "source": [
    "Xy = np.loadtxt('coimbra_cleaned.dat', dtype = 'str')\n",
    "\n",
    "print(Xy.shape)\n",
    "print(Xy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find number of unique value for each column, to have an idea about which variables are continuous, which variables are binary, category. It depends on data, however it is likely that nu = 2 --> binary; nu = 3 or 4: --> category, n > 4: continuous. Of course, we have to see data in detail as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of uniques of each variable:\n",
      "[ 51 110  50 113 116 116 115 116 113]\n"
     ]
    }
   ],
   "source": [
    "X = Xy[:,:-1]\n",
    "l,n = X.shape\n",
    "nu = np.array([len(np.unique(X[:,i])) for i in range(n)])\n",
    "print('number of uniques of each variable:')\n",
    "print(nu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i_binary: []\n",
      "i_category: []\n"
     ]
    }
   ],
   "source": [
    "i_binary = []\n",
    "i_category = []\n",
    "i_continuous = []\n",
    "for i in range(X.shape[1]):\n",
    "    nu = np.unique(X[:,i])\n",
    "    if len(nu) == 2: # binary \n",
    "        i_binary.append(i)\n",
    "    elif len(nu) < 5:\n",
    "        i_category.append(i)\n",
    "    else:\n",
    "        i_continuous.append(i)\n",
    "        \n",
    "print('i_binary:',i_binary)\n",
    "print('i_category:',i_category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then define variable type, 1: continuous, 2: binary, 3: category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "variable_type  = np.ones(n) # continuous\n",
    "variable_type[i_binary] = 2 # binary\n",
    "variable_type[i_category] = 3 # categorical\n",
    "\n",
    "print(variable_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now convert binary to +/-1, category to onehot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_binary_and_category(x,variable_type):\n",
    "    \"\"\"\n",
    "    convert binary to +-1, category to one hot; remain continuous.\n",
    "    \"\"\"\n",
    "    \n",
    "    onehot_encoder = OneHotEncoder(sparse=False,categories='auto')\n",
    "\n",
    "    # create 2 initial columns\n",
    "    x_new = np.zeros((x.shape[0],2))\n",
    "\n",
    "    for i,i_type in enumerate(variable_type):\n",
    "        if i_type == 1: # continuous\n",
    "            x_new = np.hstack((x_new,x[:,i][:,np.newaxis]))\n",
    "        elif i_type == 2: # binary\n",
    "            unique_value = np.unique(x[:,i])\n",
    "            x1 = np.array([-1. if value == unique_value[0] else 1. for value in x[:,i]])        \n",
    "            x_new = np.hstack((x_new,x1[:,np.newaxis]))\n",
    "        else: # category      \n",
    "            x1 = onehot_encoder.fit_transform(x[:,i].reshape(-1,1))\n",
    "            x_new = np.hstack((x_new,x1))        \n",
    "\n",
    "    # drop the 2 initial column\n",
    "    x_new = x_new[:,2:]\n",
    "    \n",
    "    return x_new.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(116, 9)\n",
      "[[ 48.          23.5         70.         ...   9.7024       7.99585\n",
      "  417.114     ]\n",
      " [ 83.          20.69049454  92.         ...   5.429285     4.06405\n",
      "  468.786     ]\n",
      " [ 82.          23.12467037  91.         ...  22.43204      9.27715\n",
      "  554.697     ]\n",
      " ...\n",
      " [ 65.          32.05        97.         ...  22.54        10.33\n",
      "  314.05      ]\n",
      " [ 72.          25.59        82.         ...  33.75         3.27\n",
      "  392.46      ]\n",
      " [ 86.          27.18       138.         ...  14.11         4.35\n",
      "   90.09      ]]\n"
     ]
    }
   ],
   "source": [
    "# convert X\n",
    "X_new = convert_binary_and_category(X,variable_type)\n",
    "\n",
    "print(X_new.shape)\n",
    "print(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1., 2.]), array([52, 64]))\n"
     ]
    }
   ],
   "source": [
    "## target\n",
    "y = Xy[:,-1].astype(float)\n",
    "\n",
    "print(np.unique(y,return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1.]), array([116]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "y_new = np.ones(y.shape[0])\n",
    "y_new[y =='2'] = 0\n",
    "\n",
    "\n",
    "print(np.unique(y_new,return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine X and y\n",
    "Xy_new = np.hstack((X_new,y_new[:,np.newaxis]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('coimbra_processed.dat',Xy_new,fmt='%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
