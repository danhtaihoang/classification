{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,precision_score,\\\n",
    "recall_score,roc_curve,auc\n",
    "\n",
    "#import expectation_reflection as ER\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from function import split_train_test,make_data_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, the processed data are imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1paradox' '2peptide' '3stigma' '4nki' '5mental' '6smoking' '7anemia'\n",
      " '8language' '9coag' '10tazamia' '11hepato' '12heat' '13ef' '14cervix'\n",
      " '15heart' '16liver' '17nwosu' '18school' '19ibs' '21survival' '101kidney'\n",
      " '102breast_cancer' '103diabetes_niddk' '104diabetic_retinopathy']\n"
     ]
    }
   ],
   "source": [
    "data_list = np.loadtxt('data_list.txt',dtype='str')\n",
    "\n",
    "print(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_id):    \n",
    "    data_name = data_list[data_id]\n",
    "    print('data_name:',data_name)\n",
    "    Xy = np.loadtxt('%s/data_processed.dat'%data_name) \n",
    "    X = Xy[:,:-1]\n",
    "    y = Xy[:,-1]\n",
    "\n",
    "    print(np.unique(y,return_counts=True))\n",
    "\n",
    "    X,y = make_data_balance(X,y)\n",
    "\n",
    "    print(np.unique(y,return_counts=True))\n",
    "\n",
    "    X, y = shuffle(X, y, random_state=1)\n",
    "\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.5,random_state = 1)\n",
    "    \n",
    "    sc = MinMaxScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    \n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_performance(X_train,X_test,y_train,y_test):\n",
    "    # Number of trees in random forest\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 10, stop = 100, num = 10)]\n",
    "\n",
    "    # Number of features to consider at every split\n",
    "    max_features = ['auto']\n",
    "\n",
    "    # Maximum number of levels in tree\n",
    "    max_depth = [int(x) for x in np.linspace(1, 10, num = 10)]\n",
    "    #max_depth.append(None)\n",
    "\n",
    "    # Minimum number of samples required to split a node\n",
    "    min_samples_split = [5, 10, 15, 20]\n",
    "\n",
    "    # Minimum number of samples required at each leaf node\n",
    "    min_samples_leaf = [int(x) for x in np.linspace(start = 1, stop = 5, num = 5)]\n",
    "\n",
    "    # Method of selecting samples for training each tree\n",
    "    bootstrap = [True, False]\n",
    "    \n",
    "    \n",
    "    # Create the random grid\n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "                   'max_features': max_features,\n",
    "                   'max_depth': max_depth,\n",
    "                   'min_samples_split': min_samples_split,\n",
    "                   'min_samples_leaf': min_samples_leaf,\n",
    "                   'bootstrap': bootstrap}\n",
    "    \n",
    "    random_search = RandomizedSearchCV(estimator = model, param_distributions = random_grid, n_iter = 100, \n",
    "                               cv = 4, verbose=2, random_state=1, n_jobs = -1)\n",
    "\n",
    "    random_search.fit(X_train, y_train)\n",
    "\n",
    "    # best hyper parameters\n",
    "    print(random_search.best_params_)\n",
    "\n",
    "    # performance:\n",
    "    #y_test_pred,p_test_pred = ER.predict(X_test,h0[il2_opt],w[il2_opt,:])\n",
    "    y_test_pred = random_search.best_estimator_.predict(X_test)\n",
    "    acc = accuracy_score(y_test,y_test_pred)\n",
    "    #print('Accuracy:', acc)\n",
    "    \n",
    "    p_test_pred = random_search.best_estimator_.predict_proba(X_test) # prob of [0,1]\n",
    "    p_test_pred = p_test_pred[:,1] # prob of 1    \n",
    "    fp,tp,thresholds = roc_curve(y_test, p_test_pred, drop_intermediate=False)\n",
    "    roc_auc = auc(fp,tp)\n",
    "    #print('AUC:', roc_auc)\n",
    "\n",
    "    precision = precision_score(y_test,y_test_pred)\n",
    "    #print('Precision:',precision)\n",
    "\n",
    "    recall = recall_score(y_test,y_test_pred)\n",
    "    #print('Recall:',recall)\n",
    "\n",
    "    return acc,roc_auc,precision,recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_name: 1paradox\n",
      "(array([0., 1.]), array([169,  60]))\n",
      "(array([0., 1.]), array([60, 60]))\n",
      "optimal l2: 0.1\n",
      "data_name: 2peptide\n",
      "(array([0., 1.]), array([675,  23]))\n",
      "(array([0., 1.]), array([23, 23]))\n",
      "optimal l2: 0.01\n",
      "data_name: 3stigma\n",
      "(array([0., 1.]), array([2725, 7940]))\n",
      "(array([0., 1.]), array([2725, 2725]))\n",
      "optimal l2: 0.01\n",
      "data_name: 4nki\n",
      "(array([0., 1.]), array([195,  77]))\n",
      "(array([0., 1.]), array([77, 77]))\n",
      "optimal l2: 10.0\n",
      "data_name: 5mental\n",
      "(array([0., 1.]), array([616, 147]))\n",
      "(array([0., 1.]), array([147, 147]))\n",
      "optimal l2: 10.0\n",
      "data_name: 6smoking\n",
      "(array([0., 1.]), array([852, 722]))\n",
      "(array([0., 1.]), array([722, 722]))\n",
      "optimal l2: 0.01\n",
      "data_name: 7anemia\n",
      "(array([0., 1.]), array([193,  43]))\n",
      "(array([0., 1.]), array([43, 43]))\n",
      "optimal l2: 1.0\n",
      "data_name: 8language\n",
      "(array([0., 1.]), array([896, 267]))\n",
      "(array([0., 1.]), array([267, 267]))\n",
      "optimal l2: 1.0\n",
      "data_name: 9coag\n",
      "(array([0., 1.]), array([504, 994]))\n",
      "(array([0., 1.]), array([504, 504]))\n",
      "optimal l2: 1.0\n",
      "data_name: 10tazamia\n",
      "(array([0., 1.]), array([547, 124]))\n",
      "(array([0., 1.]), array([124, 124]))\n",
      "optimal l2: 0.1\n",
      "data_name: 11hepato\n",
      "(array([0., 1.]), array([63, 99]))\n",
      "(array([0., 1.]), array([63, 63]))\n",
      "optimal l2: 100.0\n",
      "data_name: 12heat\n",
      "(array([0., 1.]), array([2492,   83]))\n",
      "(array([0., 1.]), array([83, 83]))\n",
      "optimal l2: 10.0\n",
      "data_name: 13ef\n",
      "(array([0., 1.]), array([ 93, 572]))\n",
      "(array([0., 1.]), array([93, 93]))\n",
      "optimal l2: 0.01\n",
      "data_name: 14cervix\n",
      "(array([0., 1.]), array([834,  24]))\n",
      "(array([0., 1.]), array([24, 24]))\n",
      "optimal l2: 0.01\n",
      "data_name: 15heart\n",
      "(array([0., 1.]), array([138, 165]))\n",
      "(array([0., 1.]), array([138, 138]))\n",
      "optimal l2: 1.0\n",
      "data_name: 16liver\n",
      "(array([0., 1.]), array([167, 416]))\n",
      "(array([0., 1.]), array([167, 167]))\n",
      "optimal l2: 0.01\n",
      "data_name: 17nwosu\n",
      "(array([0., 1.]), array([59, 92]))\n",
      "(array([0., 1.]), array([59, 59]))\n",
      "optimal l2: 0.01\n",
      "data_name: 18school\n",
      "(array([0., 1.]), array([  68, 3879]))\n",
      "(array([0., 1.]), array([68, 68]))\n",
      "optimal l2: 1.0\n",
      "data_name: 19ibs\n",
      "(array([0., 1.]), array([ 33, 138]))\n",
      "(array([0., 1.]), array([33, 33]))\n",
      "optimal l2: 0.01\n",
      "data_name: 21survival\n",
      "(array([0., 1.]), array([1945,  123]))\n",
      "(array([0., 1.]), array([123, 123]))\n",
      "optimal l2: 1.0\n",
      "data_name: 101kidney\n",
      "(array([0., 1.]), array([149, 223]))\n",
      "(array([0., 1.]), array([149, 149]))\n",
      "optimal l2: 0.01\n",
      "data_name: 102breast_cancer\n",
      "(array([0., 1.]), array([357, 212]))\n",
      "(array([0., 1.]), array([212, 212]))\n",
      "optimal l2: 0.01\n",
      "data_name: 103diabetes_niddk\n",
      "(array([0., 1.]), array([481, 252]))\n",
      "(array([0., 1.]), array([252, 252]))\n",
      "optimal l2: 0.1\n",
      "data_name: 104diabetic_retinopathy\n",
      "(array([0., 1.]), array([536, 611]))\n",
      "(array([0., 1.]), array([536, 536]))\n",
      "optimal l2: 0.01\n"
     ]
    }
   ],
   "source": [
    "n_data = len(data_list)\n",
    "roc_auc = np.zeros(n_data)   ; acc = np.zeros(n_data)\n",
    "precision = np.zeros(n_data) ; recall = np.zeros(n_data)\n",
    "\n",
    "data_id = 0\n",
    "#for data_id in range(n_data):\n",
    "X_train,X_test,y_train,y_test = read_data(data_id)\n",
    "acc[data_id],roc_auc[data_id],precision[data_id],recall[data_id] =\\\n",
    "           measure_performance(X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('result_RF.dat',(roc_auc,acc,precision,recall),fmt='%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
