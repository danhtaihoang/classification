{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID #</th>\n",
       "      <th>Group</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Tanner</th>\n",
       "      <th>Puberty</th>\n",
       "      <th>Race</th>\n",
       "      <th>ISF @ R</th>\n",
       "      <th>Ideal BG @ R</th>\n",
       "      <th>ICR at R</th>\n",
       "      <th>Final ISF@9mo</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 246</th>\n",
       "      <th>Unnamed: 247</th>\n",
       "      <th>Unnamed: 248</th>\n",
       "      <th>Unnamed: 249</th>\n",
       "      <th>Unnamed: 250</th>\n",
       "      <th>Unnamed: 251</th>\n",
       "      <th>Unnamed: 252</th>\n",
       "      <th>Unnamed: 253</th>\n",
       "      <th>Unnamed: 254</th>\n",
       "      <th>Unnamed: 255</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.006</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>White</td>\n",
       "      <td>15</td>\n",
       "      <td>130</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.020</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>White</td>\n",
       "      <td>50</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>White</td>\n",
       "      <td>20</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.015</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>White</td>\n",
       "      <td>30</td>\n",
       "      <td>120</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.011</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>White</td>\n",
       "      <td>25</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID #  Group Gender  Tanner  Puberty   Race  ISF @ R  Ideal BG @ R  \\\n",
       "0  0.006      0      F       5        1  White       15           130   \n",
       "1  0.020      0      F       5        1  White       50           120   \n",
       "2  0.002      0      F       5        1  White       20           120   \n",
       "3  0.015      0      F       5        1  White       30           120   \n",
       "4  0.011      0      M       4        0  White       25           120   \n",
       "\n",
       "   ICR at R  Final ISF@9mo  ...  Unnamed: 246  Unnamed: 247  Unnamed: 248  \\\n",
       "0         5             15  ...           NaN           NaN           NaN   \n",
       "1         5             30  ...           NaN           NaN           NaN   \n",
       "2         5             20  ...           NaN           NaN           NaN   \n",
       "3         4             30  ...           NaN           NaN           NaN   \n",
       "4         5             30  ...           NaN           NaN           NaN   \n",
       "\n",
       "   Unnamed: 249  Unnamed: 250  Unnamed: 251  Unnamed: 252  Unnamed: 253  \\\n",
       "0           NaN           NaN           NaN           NaN           NaN   \n",
       "1           NaN           NaN           NaN           NaN           NaN   \n",
       "2           NaN           NaN           NaN           NaN           NaN   \n",
       "3           NaN           NaN           NaN           NaN           NaN   \n",
       "4           NaN           NaN           NaN           NaN           NaN   \n",
       "\n",
       "   Unnamed: 254  Unnamed: 255  \n",
       "0           NaN           NaN  \n",
       "1           NaN           NaN  \n",
       "2           NaN           NaN  \n",
       "3           NaN           NaN  \n",
       "4           NaN           NaN  \n",
       "\n",
       "[5 rows x 256 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('diabetes.csv',sep= ',')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28 entries, 0 to 27\n",
      "Columns: 256 entries, ID # to Unnamed: 255\n",
      "dtypes: float64(233), int64(17), object(6)\n",
      "memory usage: 56.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'AN'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace empty or errors by np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace empty/erros by np.nan\n",
    "df = df.replace(r'^\\s+$', np.nan, regex=True)\n",
    "df = df.replace('\\t','',regex=True)\n",
    "df = df.replace(' ','',regex=True)\n",
    "df = df.replace('\\?',np.nan,regex=True)\n",
    "df = df.replace('\\<',np.nan,regex=True)\n",
    "#df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID #</th>\n",
       "      <th>Group</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Tanner</th>\n",
       "      <th>Puberty</th>\n",
       "      <th>Race</th>\n",
       "      <th>ISF @ R</th>\n",
       "      <th>Ideal BG @ R</th>\n",
       "      <th>ICR at R</th>\n",
       "      <th>Final ISF@9mo</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 246</th>\n",
       "      <th>Unnamed: 247</th>\n",
       "      <th>Unnamed: 248</th>\n",
       "      <th>Unnamed: 249</th>\n",
       "      <th>Unnamed: 250</th>\n",
       "      <th>Unnamed: 251</th>\n",
       "      <th>Unnamed: 252</th>\n",
       "      <th>Unnamed: 253</th>\n",
       "      <th>Unnamed: 254</th>\n",
       "      <th>Unnamed: 255</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.006</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>White</td>\n",
       "      <td>15</td>\n",
       "      <td>130</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.020</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>White</td>\n",
       "      <td>50</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>White</td>\n",
       "      <td>20</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.015</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>White</td>\n",
       "      <td>30</td>\n",
       "      <td>120</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.011</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>White</td>\n",
       "      <td>25</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 255 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID #  Group Gender  Tanner  Puberty   Race  ISF @ R  Ideal BG @ R  \\\n",
       "0  0.006      0      F       5        1  White       15           130   \n",
       "1  0.020      0      F       5        1  White       50           120   \n",
       "2  0.002      0      F       5        1  White       20           120   \n",
       "3  0.015      0      F       5        1  White       30           120   \n",
       "4  0.011      0      M       4        0  White       25           120   \n",
       "\n",
       "   ICR at R  Final ISF@9mo  ...  Unnamed: 246  Unnamed: 247  Unnamed: 248  \\\n",
       "0         5             15  ...           NaN           NaN           NaN   \n",
       "1         5             30  ...           NaN           NaN           NaN   \n",
       "2         5             20  ...           NaN           NaN           NaN   \n",
       "3         4             30  ...           NaN           NaN           NaN   \n",
       "4         5             30  ...           NaN           NaN           NaN   \n",
       "\n",
       "   Unnamed: 249  Unnamed: 250  Unnamed: 251  Unnamed: 252  Unnamed: 253  \\\n",
       "0           NaN           NaN           NaN           NaN           NaN   \n",
       "1           NaN           NaN           NaN           NaN           NaN   \n",
       "2           NaN           NaN           NaN           NaN           NaN   \n",
       "3           NaN           NaN           NaN           NaN           NaN   \n",
       "4           NaN           NaN           NaN           NaN           NaN   \n",
       "\n",
       "   Unnamed: 254  Unnamed: 255  \n",
       "0           NaN           NaN  \n",
       "1           NaN           NaN  \n",
       "2           NaN           NaN  \n",
       "3           NaN           NaN  \n",
       "4           NaN           NaN  \n",
       "\n",
       "[5 rows x 255 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the column that isn't in terms of data that can be processed by the code\n",
    "df = df.drop(['BMI % -3 mo'],axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert objects to numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n"
     ]
    }
   ],
   "source": [
    "print(np.dtype(df['Gender']))\n",
    "\n",
    "df[\"Gender\"] = pd.to_numeric(df.Gender, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n"
     ]
    }
   ],
   "source": [
    "print(np.dtype(df['Race']))\n",
    "\n",
    "df[\"Race\"] = pd.to_numeric(df.Race, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n"
     ]
    }
   ],
   "source": [
    "print(np.dtype(df['Insulin0mo']))\n",
    "\n",
    "df[\"Insulin0mo\"] = pd.to_numeric(df.Insulin0mo, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n"
     ]
    }
   ],
   "source": [
    "print(np.dtype(df['FamilyHxofT2D']))\n",
    "\n",
    "df[\"FamilyHxofT2D\"] = pd.to_numeric(df.FamilyHxofT2D, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n"
     ]
    }
   ],
   "source": [
    "print(np.dtype(df['Antibodies']))\n",
    "\n",
    "df[\"Antibodies\"] = pd.to_numeric(df.Antibodies, errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove bad columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_bad_columns(df,bad_column_threshold):\n",
    "    # find bad columns having too many missing values\n",
    "    n_null = np.array(df.isnull().sum(axis=0))\n",
    "    bad_col = np.array([]).astype(int)\n",
    "    for i in range(len(n_null)):\n",
    "        if n_null[i] >= bad_column_threshold:\n",
    "            bad_col = np.append(bad_col,i)\n",
    "\n",
    "    #print(bad_col)\n",
    "    print('number of bad columns:',len(bad_col))\n",
    "\n",
    "    # delete bad columns\n",
    "    df = df.drop(df.columns[bad_col],axis=1)\n",
    "    #df.info()\n",
    "    return df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of bad columns: 186\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28 entries, 0 to 27\n",
      "Data columns (total 69 columns):\n",
      "ID #                   28 non-null float64\n",
      "Group                  28 non-null int64\n",
      "Tanner                 28 non-null int64\n",
      "Puberty                28 non-null int64\n",
      "ISF @ R                28 non-null int64\n",
      "Ideal BG @ R           28 non-null int64\n",
      "ICR at R               28 non-null int64\n",
      "Final ISF@9mo          28 non-null int64\n",
      "Final Ideal BG@9mo     28 non-null int64\n",
      "Final ICR@9mo          28 non-null int64\n",
      "Dx Duration            28 non-null float64\n",
      "Age                    28 non-null float64\n",
      "Avg FBS -3 mo          28 non-null int64\n",
      "Avg FBS mg/dL 0 mo     28 non-null int64\n",
      "Avg FBS mmol/L 0 mo    28 non-null float64\n",
      "Ht (cm) -3 mo          28 non-null float64\n",
      "Ht SDS -3 mo           27 non-null float64\n",
      "Date 3 mo              26 non-null float64\n",
      "Age @ 3 mo             27 non-null float64\n",
      "Ht 0 mo                28 non-null float64\n",
      "Ht SDS 0 mo            27 non-null float64\n",
      "Wt (kg) -3 mo          28 non-null float64\n",
      "Wt SDS -3 mo           27 non-null float64\n",
      "Wt  0 mo               28 non-null float64\n",
      "Wt SDS 0 mo            27 non-null float64\n",
      "BMI -3 mo              28 non-null float64\n",
      "BMI SDS -3 mo          28 non-null float64\n",
      "BMI 0 mo               28 non-null float64\n",
      "BMI SDS 0 mo           28 non-null float64\n",
      "WC  at -3mo (cm)       25 non-null float64\n",
      "WC at 0 mo             27 non-null float64\n",
      "TDD a -3 mo            27 non-null float64\n",
      "TDD -3 kg              27 non-null float64\n",
      "TDD at 0 mo            28 non-null int64\n",
      "TDD 0 kg               28 non-null float64\n",
      "Levemir -3 mo          27 non-null float64\n",
      "Levemir -3 kg          27 non-null float64\n",
      "Levemir 0 mo           28 non-null int64\n",
      "Levemir 0 kg           28 non-null float64\n",
      "Novolog -3 mo          27 non-null float64\n",
      "Novolog -3 kg          27 non-null float64\n",
      "Novolog 0 mo           28 non-null int64\n",
      "Novolog 0 kg           28 non-null float64\n",
      "A1c -3 mo              28 non-null float64\n",
      "IFCC -3mo              28 non-null float64\n",
      "A1c 0 mo               28 non-null float64\n",
      "IFCC 0 mo              28 non-null float64\n",
      "AN                     28 non-null int64\n",
      "SBP 0 mo               28 non-null int64\n",
      "DBP 0 mo               28 non-null int64\n",
      "Ht (cm) +3 mo          25 non-null float64\n",
      "Wt (kg) +3 mo          25 non-null float64\n",
      "BMI +3 mo              25 non-null float64\n",
      "WC (cm) +3mo           23 non-null float64\n",
      "SBP +3 mo              25 non-null float64\n",
      "DBP +3 mo              25 non-null float64\n",
      "A1c +3m                28 non-null float64\n",
      "IFCC +3 mo             28 non-null float64\n",
      "TDD +3 mo              24 non-null float64\n",
      "TDD +3 kg              24 non-null float64\n",
      "Levemir +3 mo          25 non-null float64\n",
      "Levemir +3 mo kg       24 non-null float64\n",
      "Novolog +3 mo          24 non-null float64\n",
      "Novolog +3 mo kg       24 non-null float64\n",
      "FBS +3 mo              25 non-null float64\n",
      "A1c +6m                28 non-null float64\n",
      "IFCC +6mo              28 non-null float64\n",
      "A1c +9m                28 non-null float64\n",
      "IFCC +9mo              28 non-null float64\n",
      "dtypes: float64(52), int64(17)\n",
      "memory usage: 15.2 KB\n"
     ]
    }
   ],
   "source": [
    "df = remove_bad_columns(df,8)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove bad rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Find rows where target is missing\n",
    "def find_missing_target_rows(df,target):\n",
    "    # find rows where target is missing\n",
    "    missing_row = df[target].isnull()\n",
    "    print('Number of rows where target are missing:')\n",
    "    print(sum(missing_row))\n",
    "\n",
    "    #df = df[~missing_row]\n",
    "    missing_row_indices = np.array([t for t in range(df.shape[0]) if missing_row[t]])\n",
    "    \n",
    "    return missing_row_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows where target are missing:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "missing_target_rows = find_missing_target_rows(df,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find bad rows which contain too many missing values, then remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_bad_rows(df,bad_row_threshold):   \n",
    "    # find bad rows having too many missing values\n",
    "    n_null = np.array(df.isnull().sum(axis=1))\n",
    "    bad_row = np.array([]).astype(int)\n",
    "    for t in range(len(n_null)):\n",
    "        if n_null[t] >= bad_row_threshold:\n",
    "            bad_row = np.append(bad_row,t)\n",
    "\n",
    "    #print(bad_row)\n",
    "    print('number of bad rows:',len(bad_row))\n",
    "\n",
    "    # delete bad rows\n",
    "    #df = df.drop(bad_row)\n",
    "    #df.info()\n",
    "    return bad_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of bad rows: 6\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28 entries, 0 to 27\n",
      "Data columns (total 69 columns):\n",
      "ID #                   28 non-null float64\n",
      "Group                  28 non-null int64\n",
      "Tanner                 28 non-null int64\n",
      "Puberty                28 non-null int64\n",
      "ISF @ R                28 non-null int64\n",
      "Ideal BG @ R           28 non-null int64\n",
      "ICR at R               28 non-null int64\n",
      "Final ISF@9mo          28 non-null int64\n",
      "Final Ideal BG@9mo     28 non-null int64\n",
      "Final ICR@9mo          28 non-null int64\n",
      "Dx Duration            28 non-null float64\n",
      "Age                    28 non-null float64\n",
      "Avg FBS -3 mo          28 non-null int64\n",
      "Avg FBS mg/dL 0 mo     28 non-null int64\n",
      "Avg FBS mmol/L 0 mo    28 non-null float64\n",
      "Ht (cm) -3 mo          28 non-null float64\n",
      "Ht SDS -3 mo           27 non-null float64\n",
      "Date 3 mo              26 non-null float64\n",
      "Age @ 3 mo             27 non-null float64\n",
      "Ht 0 mo                28 non-null float64\n",
      "Ht SDS 0 mo            27 non-null float64\n",
      "Wt (kg) -3 mo          28 non-null float64\n",
      "Wt SDS -3 mo           27 non-null float64\n",
      "Wt  0 mo               28 non-null float64\n",
      "Wt SDS 0 mo            27 non-null float64\n",
      "BMI -3 mo              28 non-null float64\n",
      "BMI SDS -3 mo          28 non-null float64\n",
      "BMI 0 mo               28 non-null float64\n",
      "BMI SDS 0 mo           28 non-null float64\n",
      "WC  at -3mo (cm)       25 non-null float64\n",
      "WC at 0 mo             27 non-null float64\n",
      "TDD a -3 mo            27 non-null float64\n",
      "TDD -3 kg              27 non-null float64\n",
      "TDD at 0 mo            28 non-null int64\n",
      "TDD 0 kg               28 non-null float64\n",
      "Levemir -3 mo          27 non-null float64\n",
      "Levemir -3 kg          27 non-null float64\n",
      "Levemir 0 mo           28 non-null int64\n",
      "Levemir 0 kg           28 non-null float64\n",
      "Novolog -3 mo          27 non-null float64\n",
      "Novolog -3 kg          27 non-null float64\n",
      "Novolog 0 mo           28 non-null int64\n",
      "Novolog 0 kg           28 non-null float64\n",
      "A1c -3 mo              28 non-null float64\n",
      "IFCC -3mo              28 non-null float64\n",
      "A1c 0 mo               28 non-null float64\n",
      "IFCC 0 mo              28 non-null float64\n",
      "AN                     28 non-null int64\n",
      "SBP 0 mo               28 non-null int64\n",
      "DBP 0 mo               28 non-null int64\n",
      "Ht (cm) +3 mo          25 non-null float64\n",
      "Wt (kg) +3 mo          25 non-null float64\n",
      "BMI +3 mo              25 non-null float64\n",
      "WC (cm) +3mo           23 non-null float64\n",
      "SBP +3 mo              25 non-null float64\n",
      "DBP +3 mo              25 non-null float64\n",
      "A1c +3m                28 non-null float64\n",
      "IFCC +3 mo             28 non-null float64\n",
      "TDD +3 mo              24 non-null float64\n",
      "TDD +3 kg              24 non-null float64\n",
      "Levemir +3 mo          25 non-null float64\n",
      "Levemir +3 mo kg       24 non-null float64\n",
      "Novolog +3 mo          24 non-null float64\n",
      "Novolog +3 mo kg       24 non-null float64\n",
      "FBS +3 mo              25 non-null float64\n",
      "A1c +6m                28 non-null float64\n",
      "IFCC +6mo              28 non-null float64\n",
      "A1c +9m                28 non-null float64\n",
      "IFCC +9mo              28 non-null float64\n",
      "dtypes: float64(52), int64(17)\n",
      "memory usage: 15.2 KB\n"
     ]
    }
   ],
   "source": [
    "bad_rows = find_bad_rows(df,5)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows need to delete: 6\n"
     ]
    }
   ],
   "source": [
    "del_rows = np.union1d(missing_target_rows,bad_rows)\n",
    "print('number of rows need to delete:',len(del_rows))\n",
    "\n",
    "df = df.drop(del_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate target and attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx = df.drop(target,axis=1)\n",
    "dfy = df[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find variable type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of uniques of each variable:\n",
      "[22  2  4  2  5  5  8  5  6  8 21 22 20 21 21 19 22 21 21 22 22 22 22 21\n",
      " 22 22 22 22 19 20 21 19 22 22 22 16 22 20 22 20 22 17 22 18 18 15 15 18\n",
      " 17 20 21 22 18 16 14 14 14 21 20 16 20 17 20 19 16 16 18 18]\n"
     ]
    }
   ],
   "source": [
    "# number of uniques of each column (excluding NaN)\n",
    "nu = np.array([len(pd.unique(dfx[col].dropna())) for col in dfx.columns])\n",
    "print('number of uniques of each variable:')\n",
    "print(nu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def define_variable_type(df,nu):\n",
    "    i_binary = [] ; i_category = [] ; i_continuous = []\n",
    "    for i in range(len(nu)):\n",
    "        if nu[i] == 2: # binary \n",
    "            i_binary.append(i)\n",
    "        elif nu[i] < 5: # !!!! NOTE: this is not always correct, depending on data\n",
    "            i_category.append(i)\n",
    "        else:\n",
    "            i_continuous.append(i)\n",
    "\n",
    "    print('i_binary:',i_binary)\n",
    "    print('i_category:',i_category)   \n",
    "    #i_binary, i_category, i_continuous\n",
    "    \n",
    "    variable_type  = np.ones(len(nu))  # binary\n",
    "    variable_type[i_category] = 2   # categorical\n",
    "    variable_type[i_continuous] = 3 # continuous\n",
    "\n",
    "    return variable_type #,i_binary,i_category,i_continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i_binary: [1, 3]\n",
      "i_category: [2]\n",
      "variable type: [3. 1. 2. 1. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "variable_type = define_variable_type(dfx,nu)\n",
    "print('variable type:',variable_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute missing values of attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing(df,variable_type):\n",
    "    # impute binary and categorical variables by the most frequency (in each column)\n",
    "    # continuous variable by median\n",
    "    # input: df: pandas data frame, variable_type: list\n",
    "    # output: df2: pandas data frame\n",
    "    df2 = df.copy()\n",
    "    for i,col in enumerate(df.columns):\n",
    "        if variable_type[i] < 3: # binary or caterogy\n",
    "            df2[col] = df[col].fillna(df[col].mode().iloc[0])\n",
    "        else: # continuous\n",
    "            df2[col] = df[col].fillna(df[col].median())    \n",
    "    return df2       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 22 entries, 0 to 26\n",
      "Data columns (total 68 columns):\n",
      "ID #                   22 non-null float64\n",
      "Group                  22 non-null int64\n",
      "Tanner                 22 non-null int64\n",
      "Puberty                22 non-null int64\n",
      "ISF @ R                22 non-null int64\n",
      "Ideal BG @ R           22 non-null int64\n",
      "ICR at R               22 non-null int64\n",
      "Final ISF@9mo          22 non-null int64\n",
      "Final Ideal BG@9mo     22 non-null int64\n",
      "Final ICR@9mo          22 non-null int64\n",
      "Dx Duration            22 non-null float64\n",
      "Age                    22 non-null float64\n",
      "Avg FBS -3 mo          22 non-null int64\n",
      "Avg FBS mg/dL 0 mo     22 non-null int64\n",
      "Avg FBS mmol/L 0 mo    22 non-null float64\n",
      "Ht (cm) -3 mo          22 non-null float64\n",
      "Ht SDS -3 mo           22 non-null float64\n",
      "Date 3 mo              22 non-null float64\n",
      "Age @ 3 mo             22 non-null float64\n",
      "Ht 0 mo                22 non-null float64\n",
      "Ht SDS 0 mo            22 non-null float64\n",
      "Wt (kg) -3 mo          22 non-null float64\n",
      "Wt SDS -3 mo           22 non-null float64\n",
      "Wt  0 mo               22 non-null float64\n",
      "Wt SDS 0 mo            22 non-null float64\n",
      "BMI -3 mo              22 non-null float64\n",
      "BMI SDS -3 mo          22 non-null float64\n",
      "BMI 0 mo               22 non-null float64\n",
      "BMI SDS 0 mo           22 non-null float64\n",
      "WC  at -3mo (cm)       22 non-null float64\n",
      "WC at 0 mo             22 non-null float64\n",
      "TDD a -3 mo            22 non-null float64\n",
      "TDD -3 kg              22 non-null float64\n",
      "TDD at 0 mo            22 non-null int64\n",
      "TDD 0 kg               22 non-null float64\n",
      "Levemir -3 mo          22 non-null float64\n",
      "Levemir -3 kg          22 non-null float64\n",
      "Levemir 0 mo           22 non-null int64\n",
      "Levemir 0 kg           22 non-null float64\n",
      "Novolog -3 mo          22 non-null float64\n",
      "Novolog -3 kg          22 non-null float64\n",
      "Novolog 0 mo           22 non-null int64\n",
      "Novolog 0 kg           22 non-null float64\n",
      "A1c -3 mo              22 non-null float64\n",
      "IFCC -3mo              22 non-null float64\n",
      "A1c 0 mo               22 non-null float64\n",
      "IFCC 0 mo              22 non-null float64\n",
      "SBP 0 mo               22 non-null int64\n",
      "DBP 0 mo               22 non-null int64\n",
      "Ht (cm) +3 mo          22 non-null float64\n",
      "Wt (kg) +3 mo          22 non-null float64\n",
      "BMI +3 mo              22 non-null float64\n",
      "WC (cm) +3mo           22 non-null float64\n",
      "SBP +3 mo              22 non-null float64\n",
      "DBP +3 mo              22 non-null float64\n",
      "A1c +3m                22 non-null float64\n",
      "IFCC +3 mo             22 non-null float64\n",
      "TDD +3 mo              22 non-null float64\n",
      "TDD +3 kg              22 non-null float64\n",
      "Levemir +3 mo          22 non-null float64\n",
      "Levemir +3 mo kg       22 non-null float64\n",
      "Novolog +3 mo          22 non-null float64\n",
      "Novolog +3 mo kg       22 non-null float64\n",
      "FBS +3 mo              22 non-null float64\n",
      "A1c +6m                22 non-null float64\n",
      "IFCC +6mo              22 non-null float64\n",
      "A1c +9m                22 non-null float64\n",
      "IFCC +9mo              22 non-null float64\n",
      "dtypes: float64(52), int64(16)\n",
      "memory usage: 11.9 KB\n"
     ]
    }
   ],
   "source": [
    "dfx_imputed = impute_missing(dfx,variable_type)\n",
    "dfx_imputed.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_binary_and_category(x,variable_type):\n",
    "    \"\"\"\n",
    "    convert binary to +-1, category to one hot; remain continuous.\n",
    "    \"\"\"    \n",
    "    onehot_encoder = OneHotEncoder(sparse=False,categories='auto')\n",
    "\n",
    "    # create 2 initial columns\n",
    "    x_new = np.zeros((x.shape[0],2))\n",
    "\n",
    "    for i,i_type in enumerate(variable_type):\n",
    "        if i_type == 1: # binary\n",
    "            unique_value = np.unique(x[:,i])\n",
    "            x1 = np.array([-1. if value == unique_value[0] else 1. for value in x[:,i]])        \n",
    "            x_new = np.hstack((x_new,x1[:,np.newaxis]))\n",
    "\n",
    "        elif i_type == 2: # category\n",
    "            x1 = onehot_encoder.fit_transform(x[:,i].reshape(-1,1))\n",
    "            x_new = np.hstack((x_new,x1))\n",
    "            \n",
    "        else: # continuous      \n",
    "            x_new = np.hstack((x_new,x[:,i][:,np.newaxis]))      \n",
    "\n",
    "    # drop the 2 initial column\n",
    "    x_new = x_new[:,2:]\n",
    "    \n",
    "    return x_new.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 71)\n",
      "[[ 6.0000e-03 -1.0000e+00  0.0000e+00 ...  7.7040e+01  8.8000e+00\n",
      "   7.2670e+01]\n",
      " [ 2.0000e-02 -1.0000e+00  0.0000e+00 ...  6.7210e+01  8.1000e+00\n",
      "   6.5020e+01]\n",
      " [ 1.5000e-02 -1.0000e+00  0.0000e+00 ...  6.8300e+01  8.3000e+00\n",
      "   6.7210e+01]\n",
      " ...\n",
      " [ 1.3000e-02  1.0000e+00  0.0000e+00 ...  6.2830e+01  7.8000e+00\n",
      "   6.1740e+01]\n",
      " [ 3.0000e-03  1.0000e+00  0.0000e+00 ...  6.6110e+01  1.0000e+01\n",
      "   8.5790e+01]\n",
      " [ 1.8000e-02  1.0000e+00  0.0000e+00 ...  1.0328e+02  1.4400e+01\n",
      "   1.3389e+02]]\n"
     ]
    }
   ],
   "source": [
    "# convert x\n",
    "x = np.array(dfx_imputed)\n",
    "x_new = convert_binary_and_category(x,variable_type)\n",
    "\n",
    "print(x_new.shape)\n",
    "print(x_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([13,  9]))\n",
      "(array([0, 1]), array([13,  9]))\n"
     ]
    }
   ],
   "source": [
    "y = np.array(dfy)\n",
    "print(np.unique(y,return_counts=True))\n",
    "\n",
    "# convert target to 0 and 1\n",
    "#y_new = np.ones(y.shape[0])\n",
    "#y_new[y =='Neg'] = 0\n",
    "\n",
    "# if target is already 0 and 1\n",
    "y_new = y #and delete lines below convert  \n",
    "print(np.unique(y_new,return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine X and y and save to a file\n",
    "xy_new = np.hstack((x_new,y_new[:,np.newaxis]))\n",
    "np.savetxt('diabetes_processed.dat',xy_new,fmt='%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
