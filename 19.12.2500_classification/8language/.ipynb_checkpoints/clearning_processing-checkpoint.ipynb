{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>filename</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>age_years</th>\n",
       "      <th>corpus</th>\n",
       "      <th>group</th>\n",
       "      <th>child_TNW</th>\n",
       "      <th>child_TNS</th>\n",
       "      <th>examiner_TNW</th>\n",
       "      <th>...</th>\n",
       "      <th>word_errors</th>\n",
       "      <th>f_k</th>\n",
       "      <th>n_v</th>\n",
       "      <th>n_aux</th>\n",
       "      <th>n_3s_v</th>\n",
       "      <th>det_n_pl</th>\n",
       "      <th>det_pl_n</th>\n",
       "      <th>pro_aux</th>\n",
       "      <th>pro_3s_v</th>\n",
       "      <th>total_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>fssli009.cha</td>\n",
       "      <td>NaN</td>\n",
       "      <td>165</td>\n",
       "      <td>13.750000</td>\n",
       "      <td>Conti4</td>\n",
       "      <td>SLI</td>\n",
       "      <td>287</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1.210456</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>fssli058.cha</td>\n",
       "      <td>NaN</td>\n",
       "      <td>172</td>\n",
       "      <td>14.333333</td>\n",
       "      <td>Conti4</td>\n",
       "      <td>SLI</td>\n",
       "      <td>368</td>\n",
       "      <td>42</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>1.871708</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>fssli062.cha</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>Conti4</td>\n",
       "      <td>SLI</td>\n",
       "      <td>266</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.240602</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>fssli066.cha</td>\n",
       "      <td>NaN</td>\n",
       "      <td>184</td>\n",
       "      <td>15.333333</td>\n",
       "      <td>Conti4</td>\n",
       "      <td>SLI</td>\n",
       "      <td>405</td>\n",
       "      <td>40</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1.877762</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>fssli108.cha</td>\n",
       "      <td>NaN</td>\n",
       "      <td>176</td>\n",
       "      <td>14.666667</td>\n",
       "      <td>Conti4</td>\n",
       "      <td>SLI</td>\n",
       "      <td>300</td>\n",
       "      <td>35</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.339524</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Y      filename  sex  age  age_years  corpus group  child_TNW  child_TNS  \\\n",
       "0  1  fssli009.cha  NaN  165  13.750000  Conti4   SLI        287         36   \n",
       "1  1  fssli058.cha  NaN  172  14.333333  Conti4   SLI        368         42   \n",
       "2  1  fssli062.cha  NaN  160  13.333333  Conti4   SLI        266         26   \n",
       "3  1  fssli066.cha  NaN  184  15.333333  Conti4   SLI        405         40   \n",
       "4  1  fssli108.cha  NaN  176  14.666667  Conti4   SLI        300         35   \n",
       "\n",
       "   examiner_TNW  ...  word_errors       f_k  n_v  n_aux  n_3s_v  det_n_pl  \\\n",
       "0             4  ...            8  1.210456    0      2       2         7   \n",
       "1            27  ...           16  1.871708    0      4       0         5   \n",
       "2             2  ...            0  2.240602    0      1       0         5   \n",
       "3            21  ...            4  1.877762    1      0       0        11   \n",
       "4            20  ...            8  0.339524    0      1       1         5   \n",
       "\n",
       "   det_pl_n  pro_aux  pro_3s_v  total_error  \n",
       "0         0        0         1           12  \n",
       "1         0        0         0            9  \n",
       "2         0        0         0            6  \n",
       "3         0        0         0           12  \n",
       "4         0        0         0            7  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"language.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1163 entries, 0 to 1162\n",
      "Data columns (total 64 columns):\n",
      "Y                        1163 non-null int64\n",
      "filename                 1163 non-null object\n",
      "sex                      1044 non-null object\n",
      "age                      1163 non-null int64\n",
      "age_years                1163 non-null float64\n",
      "corpus                   1163 non-null object\n",
      "group                    1163 non-null object\n",
      "child_TNW                1163 non-null int64\n",
      "child_TNS                1163 non-null int64\n",
      "examiner_TNW             1163 non-null int64\n",
      "freq_ttr                 1163 non-null float64\n",
      "r_2_i_verbs              1163 non-null float64\n",
      "mor_words                1163 non-null int64\n",
      "num_pos_tags             1163 non-null int64\n",
      "n_dos                    1163 non-null int64\n",
      "repetition               1163 non-null int64\n",
      "retracing                1163 non-null int64\n",
      "fillers                  1163 non-null int64\n",
      "s_1g_ppl                 1163 non-null float64\n",
      "s_2g_ppl                 1163 non-null float64\n",
      "s_3g_ppl                 1163 non-null float64\n",
      "d_1g_ppl                 1163 non-null float64\n",
      "d_2g_ppl                 1163 non-null float64\n",
      "d_3g_ppl                 1163 non-null float64\n",
      "z_mlu_sli                1163 non-null float64\n",
      "z_mlu_td                 1163 non-null float64\n",
      "z_word_errors_sli        1163 non-null float64\n",
      "z_word_errors_td         1163 non-null float64\n",
      "z_r_2_i_verbs_sli        1163 non-null float64\n",
      "z_r_2_i_verbs_td         1163 non-null float64\n",
      "z_utts_sli               1163 non-null float64\n",
      "z_utts_td                1163 non-null float64\n",
      "total_syl                1163 non-null int64\n",
      "average_syl              1163 non-null float64\n",
      "mlu_words                1163 non-null float64\n",
      "mlu_morphemes            1163 non-null float64\n",
      "mlu100_utts              1163 non-null int64\n",
      "verb_utt                 1163 non-null float64\n",
      "dss                      1163 non-null float64\n",
      "ipsyn_total              1163 non-null int64\n",
      "present_progressive      1163 non-null int64\n",
      "propositions_in          1163 non-null int64\n",
      "propositions_on          1163 non-null int64\n",
      "plural_s                 1163 non-null int64\n",
      "irregular_past_tense     1163 non-null int64\n",
      "possessive_s             1163 non-null int64\n",
      "uncontractible_copula    1163 non-null int64\n",
      "articles                 1163 non-null int64\n",
      "regular_past_ed          1163 non-null int64\n",
      "regular_3rd_person_s     1163 non-null int64\n",
      "irregular_3rd_person     1163 non-null int64\n",
      "uncontractible_aux       1163 non-null int64\n",
      "contractible_copula      1163 non-null int64\n",
      "contractible_aux         1163 non-null int64\n",
      "word_errors              1163 non-null int64\n",
      "f_k                      1163 non-null float64\n",
      "n_v                      1163 non-null int64\n",
      "n_aux                    1163 non-null int64\n",
      "n_3s_v                   1163 non-null int64\n",
      "det_n_pl                 1163 non-null int64\n",
      "det_pl_n                 1163 non-null int64\n",
      "pro_aux                  1163 non-null int64\n",
      "pro_3s_v                 1163 non-null int64\n",
      "total_error              1163 non-null int64\n",
      "dtypes: float64(23), int64(37), object(4)\n",
      "memory usage: 581.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Y'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace empty or errors by np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace empty/erros by np.nan\n",
    "df = df.replace(r'^\\s+$', np.nan, regex=True)\n",
    "df = df.replace('\\t','',regex=True)\n",
    "df = df.replace(' ','',regex=True)\n",
    "df = df.replace('\\?',np.nan,regex=True)\n",
    "df = df.replace('\\<',np.nan,regex=True)\n",
    "df = df.replace('#NULL!',np.nan,regex=True)\n",
    "#df = df.replace('99',np.nan,regex=True)\n",
    "#df = df.replace(99,np.nan,regex=True)\n",
    "#df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>age_years</th>\n",
       "      <th>child_TNW</th>\n",
       "      <th>child_TNS</th>\n",
       "      <th>examiner_TNW</th>\n",
       "      <th>freq_ttr</th>\n",
       "      <th>r_2_i_verbs</th>\n",
       "      <th>mor_words</th>\n",
       "      <th>...</th>\n",
       "      <th>word_errors</th>\n",
       "      <th>f_k</th>\n",
       "      <th>n_v</th>\n",
       "      <th>n_aux</th>\n",
       "      <th>n_3s_v</th>\n",
       "      <th>det_n_pl</th>\n",
       "      <th>det_pl_n</th>\n",
       "      <th>pro_aux</th>\n",
       "      <th>pro_3s_v</th>\n",
       "      <th>total_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>165</td>\n",
       "      <td>13.750000</td>\n",
       "      <td>287</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.108108</td>\n",
       "      <td>252</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1.210456</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>172</td>\n",
       "      <td>14.333333</td>\n",
       "      <td>368</td>\n",
       "      <td>42</td>\n",
       "      <td>27</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>361</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>1.871708</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>266</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>246</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.240602</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>184</td>\n",
       "      <td>15.333333</td>\n",
       "      <td>405</td>\n",
       "      <td>40</td>\n",
       "      <td>21</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.148936</td>\n",
       "      <td>348</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1.877762</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>176</td>\n",
       "      <td>14.666667</td>\n",
       "      <td>300</td>\n",
       "      <td>35</td>\n",
       "      <td>20</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>294</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.339524</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Y  sex  age  age_years  child_TNW  child_TNS  examiner_TNW  freq_ttr  \\\n",
       "0  1  NaN  165  13.750000        287         36             4     0.333   \n",
       "1  1  NaN  172  14.333333        368         42            27     0.274   \n",
       "2  1  NaN  160  13.333333        266         26             2     0.411   \n",
       "3  1  NaN  184  15.333333        405         40            21     0.359   \n",
       "4  1  NaN  176  14.666667        300         35            20     0.279   \n",
       "\n",
       "   r_2_i_verbs  mor_words  ...  word_errors       f_k  n_v  n_aux  n_3s_v  \\\n",
       "0     0.108108        252  ...            8  1.210456    0      2       2   \n",
       "1     0.050000        361  ...           16  1.871708    0      4       0   \n",
       "2     0.105263        246  ...            0  2.240602    0      1       0   \n",
       "3     0.148936        348  ...            4  1.877762    1      0       0   \n",
       "4     0.150000        294  ...            8  0.339524    0      1       1   \n",
       "\n",
       "   det_n_pl  det_pl_n  pro_aux  pro_3s_v  total_error  \n",
       "0         7         0        0         1           12  \n",
       "1         5         0        0         0            9  \n",
       "2         5         0        0         0            6  \n",
       "3        11         0        0         0           12  \n",
       "4         5         0        0         0            7  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the column outliers as it is unrelated to the dependent variable\n",
    "outliers = ['filename','corpus','group']\n",
    "df = df.drop(outliers,axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove bad columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_bad_columns(df,bad_column_threshold):\n",
    "    # find bad columns having too many missing values\n",
    "    n_null = np.array(df.isnull().sum(axis=0))\n",
    "    bad_col = np.array([]).astype(int)\n",
    "    for i in range(len(n_null)):\n",
    "        if n_null[i] >= bad_column_threshold:\n",
    "            bad_col = np.append(bad_col,i)\n",
    "\n",
    "    #print(bad_col)\n",
    "    print('number of bad columns:',len(bad_col))\n",
    "\n",
    "    # delete bad columns\n",
    "    df = df.drop(df.columns[bad_col],axis=1)\n",
    "    #df.info()\n",
    "    return df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of bad columns: 1\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1163 entries, 0 to 1162\n",
      "Data columns (total 60 columns):\n",
      "Y                        1163 non-null int64\n",
      "age                      1163 non-null int64\n",
      "age_years                1163 non-null float64\n",
      "child_TNW                1163 non-null int64\n",
      "child_TNS                1163 non-null int64\n",
      "examiner_TNW             1163 non-null int64\n",
      "freq_ttr                 1163 non-null float64\n",
      "r_2_i_verbs              1163 non-null float64\n",
      "mor_words                1163 non-null int64\n",
      "num_pos_tags             1163 non-null int64\n",
      "n_dos                    1163 non-null int64\n",
      "repetition               1163 non-null int64\n",
      "retracing                1163 non-null int64\n",
      "fillers                  1163 non-null int64\n",
      "s_1g_ppl                 1163 non-null float64\n",
      "s_2g_ppl                 1163 non-null float64\n",
      "s_3g_ppl                 1163 non-null float64\n",
      "d_1g_ppl                 1163 non-null float64\n",
      "d_2g_ppl                 1163 non-null float64\n",
      "d_3g_ppl                 1163 non-null float64\n",
      "z_mlu_sli                1163 non-null float64\n",
      "z_mlu_td                 1163 non-null float64\n",
      "z_word_errors_sli        1163 non-null float64\n",
      "z_word_errors_td         1163 non-null float64\n",
      "z_r_2_i_verbs_sli        1163 non-null float64\n",
      "z_r_2_i_verbs_td         1163 non-null float64\n",
      "z_utts_sli               1163 non-null float64\n",
      "z_utts_td                1163 non-null float64\n",
      "total_syl                1163 non-null int64\n",
      "average_syl              1163 non-null float64\n",
      "mlu_words                1163 non-null float64\n",
      "mlu_morphemes            1163 non-null float64\n",
      "mlu100_utts              1163 non-null int64\n",
      "verb_utt                 1163 non-null float64\n",
      "dss                      1163 non-null float64\n",
      "ipsyn_total              1163 non-null int64\n",
      "present_progressive      1163 non-null int64\n",
      "propositions_in          1163 non-null int64\n",
      "propositions_on          1163 non-null int64\n",
      "plural_s                 1163 non-null int64\n",
      "irregular_past_tense     1163 non-null int64\n",
      "possessive_s             1163 non-null int64\n",
      "uncontractible_copula    1163 non-null int64\n",
      "articles                 1163 non-null int64\n",
      "regular_past_ed          1163 non-null int64\n",
      "regular_3rd_person_s     1163 non-null int64\n",
      "irregular_3rd_person     1163 non-null int64\n",
      "uncontractible_aux       1163 non-null int64\n",
      "contractible_copula      1163 non-null int64\n",
      "contractible_aux         1163 non-null int64\n",
      "word_errors              1163 non-null int64\n",
      "f_k                      1163 non-null float64\n",
      "n_v                      1163 non-null int64\n",
      "n_aux                    1163 non-null int64\n",
      "n_3s_v                   1163 non-null int64\n",
      "det_n_pl                 1163 non-null int64\n",
      "det_pl_n                 1163 non-null int64\n",
      "pro_aux                  1163 non-null int64\n",
      "pro_3s_v                 1163 non-null int64\n",
      "total_error              1163 non-null int64\n",
      "dtypes: float64(23), int64(37)\n",
      "memory usage: 545.2 KB\n"
     ]
    }
   ],
   "source": [
    "df = remove_bad_columns(df,3)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove bad rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Find rows where target is missing\n",
    "def find_missing_target_rows(df,target):\n",
    "    # find rows where target is missing\n",
    "    missing_row = df[target].isnull()\n",
    "    print('Number of rows where target are missing:')\n",
    "    print(sum(missing_row))\n",
    "\n",
    "    #df = df[~missing_row]\n",
    "    missing_row_indices = np.array([t for t in range(df.shape[0]) if missing_row[t]])\n",
    "    \n",
    "    return missing_row_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows where target are missing:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "missing_target_rows = find_missing_target_rows(df,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find bad rows which contain too many missing values, then remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_bad_rows(df,bad_row_threshold):   \n",
    "    # find bad rows having too many missing values\n",
    "    n_null = np.array(df.isnull().sum(axis=1))\n",
    "    bad_row = np.array([]).astype(int)\n",
    "    for t in range(len(n_null)):\n",
    "        if n_null[t] >= bad_row_threshold:\n",
    "            bad_row = np.append(bad_row,t)\n",
    "\n",
    "    #print(bad_row)\n",
    "    print('number of bad rows:',len(bad_row))\n",
    "\n",
    "    # delete bad rows\n",
    "    #df = df.drop(bad_row)\n",
    "    #df.info()\n",
    "    return bad_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of bad rows: 0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1163 entries, 0 to 1162\n",
      "Data columns (total 60 columns):\n",
      "Y                        1163 non-null int64\n",
      "age                      1163 non-null int64\n",
      "age_years                1163 non-null float64\n",
      "child_TNW                1163 non-null int64\n",
      "child_TNS                1163 non-null int64\n",
      "examiner_TNW             1163 non-null int64\n",
      "freq_ttr                 1163 non-null float64\n",
      "r_2_i_verbs              1163 non-null float64\n",
      "mor_words                1163 non-null int64\n",
      "num_pos_tags             1163 non-null int64\n",
      "n_dos                    1163 non-null int64\n",
      "repetition               1163 non-null int64\n",
      "retracing                1163 non-null int64\n",
      "fillers                  1163 non-null int64\n",
      "s_1g_ppl                 1163 non-null float64\n",
      "s_2g_ppl                 1163 non-null float64\n",
      "s_3g_ppl                 1163 non-null float64\n",
      "d_1g_ppl                 1163 non-null float64\n",
      "d_2g_ppl                 1163 non-null float64\n",
      "d_3g_ppl                 1163 non-null float64\n",
      "z_mlu_sli                1163 non-null float64\n",
      "z_mlu_td                 1163 non-null float64\n",
      "z_word_errors_sli        1163 non-null float64\n",
      "z_word_errors_td         1163 non-null float64\n",
      "z_r_2_i_verbs_sli        1163 non-null float64\n",
      "z_r_2_i_verbs_td         1163 non-null float64\n",
      "z_utts_sli               1163 non-null float64\n",
      "z_utts_td                1163 non-null float64\n",
      "total_syl                1163 non-null int64\n",
      "average_syl              1163 non-null float64\n",
      "mlu_words                1163 non-null float64\n",
      "mlu_morphemes            1163 non-null float64\n",
      "mlu100_utts              1163 non-null int64\n",
      "verb_utt                 1163 non-null float64\n",
      "dss                      1163 non-null float64\n",
      "ipsyn_total              1163 non-null int64\n",
      "present_progressive      1163 non-null int64\n",
      "propositions_in          1163 non-null int64\n",
      "propositions_on          1163 non-null int64\n",
      "plural_s                 1163 non-null int64\n",
      "irregular_past_tense     1163 non-null int64\n",
      "possessive_s             1163 non-null int64\n",
      "uncontractible_copula    1163 non-null int64\n",
      "articles                 1163 non-null int64\n",
      "regular_past_ed          1163 non-null int64\n",
      "regular_3rd_person_s     1163 non-null int64\n",
      "irregular_3rd_person     1163 non-null int64\n",
      "uncontractible_aux       1163 non-null int64\n",
      "contractible_copula      1163 non-null int64\n",
      "contractible_aux         1163 non-null int64\n",
      "word_errors              1163 non-null int64\n",
      "f_k                      1163 non-null float64\n",
      "n_v                      1163 non-null int64\n",
      "n_aux                    1163 non-null int64\n",
      "n_3s_v                   1163 non-null int64\n",
      "det_n_pl                 1163 non-null int64\n",
      "det_pl_n                 1163 non-null int64\n",
      "pro_aux                  1163 non-null int64\n",
      "pro_3s_v                 1163 non-null int64\n",
      "total_error              1163 non-null int64\n",
      "dtypes: float64(23), int64(37)\n",
      "memory usage: 545.2 KB\n"
     ]
    }
   ],
   "source": [
    "bad_rows = find_bad_rows(df,3)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows need to delete: 0\n"
     ]
    }
   ],
   "source": [
    "del_rows = np.union1d(missing_target_rows,bad_rows)\n",
    "print('number of rows need to delete:',len(del_rows))\n",
    "\n",
    "df = df.drop(del_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate target and attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx = df.drop(target,axis=1)\n",
    "dfy = df[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find variable type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of uniques of each variable:\n",
      "[ 129  129  611  133   99  396  643  578   51   13   59   48   52 1160\n",
      " 1161 1162 1158 1161 1156  970  970   13   13  643  643  133  133  664\n",
      " 1095  970  978   93  592  628   81   56   16   17   30  103   12   43\n",
      "  129   44   58   60   51   11   17   13 1161   16   24   25   32    3\n",
      "    3   22   61]\n"
     ]
    }
   ],
   "source": [
    "# number of uniques of each column (excluding NaN)\n",
    "nu = np.array([len(pd.unique(dfx[col].dropna())) for col in dfx.columns])\n",
    "print('number of uniques of each variable:')\n",
    "print(nu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def define_variable_type(df,nu):\n",
    "    i_binary = [] ; i_category = [] ; i_continuous = []\n",
    "    for i in range(len(nu)):\n",
    "        if nu[i] == 2: # binary \n",
    "            i_binary.append(i)\n",
    "        elif nu[i] < 5: # !!!! NOTE: this is not always correct, depending on data\n",
    "            i_category.append(i)\n",
    "        else:\n",
    "            i_continuous.append(i)\n",
    "\n",
    "    print('i_binary:',i_binary)\n",
    "    print('i_category:',i_category)   \n",
    "    #i_binary, i_category, i_continuous\n",
    "    \n",
    "    variable_type  = np.ones(len(nu))  # binary\n",
    "    variable_type[i_category] = 2   # categorical\n",
    "    variable_type[i_continuous] = 3 # continuous\n",
    "\n",
    "    return variable_type #,i_binary,i_category,i_continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i_binary: []\n",
      "i_category: [55, 56]\n",
      "variable type: [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 2. 2. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "variable_type = define_variable_type(dfx,nu)\n",
    "print('variable type:',variable_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute missing values of attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing(df,variable_type):\n",
    "    # impute binary and categorical variables by the most frequency (in each column)\n",
    "    # continuous variable by median\n",
    "    # input: df: pandas data frame, variable_type: list\n",
    "    # output: df2: pandas data frame\n",
    "    df2 = df.copy()\n",
    "    for i,col in enumerate(df.columns):\n",
    "        if variable_type[i] < 3: # binary or caterogy\n",
    "            df2[col] = df[col].fillna(df[col].mode().iloc[0])\n",
    "        else: # continuous\n",
    "            df2[col] = df[col].fillna(df[col].median())    \n",
    "    return df2       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1163 entries, 0 to 1162\n",
      "Data columns (total 59 columns):\n",
      "age                      1163 non-null int64\n",
      "age_years                1163 non-null float64\n",
      "child_TNW                1163 non-null int64\n",
      "child_TNS                1163 non-null int64\n",
      "examiner_TNW             1163 non-null int64\n",
      "freq_ttr                 1163 non-null float64\n",
      "r_2_i_verbs              1163 non-null float64\n",
      "mor_words                1163 non-null int64\n",
      "num_pos_tags             1163 non-null int64\n",
      "n_dos                    1163 non-null int64\n",
      "repetition               1163 non-null int64\n",
      "retracing                1163 non-null int64\n",
      "fillers                  1163 non-null int64\n",
      "s_1g_ppl                 1163 non-null float64\n",
      "s_2g_ppl                 1163 non-null float64\n",
      "s_3g_ppl                 1163 non-null float64\n",
      "d_1g_ppl                 1163 non-null float64\n",
      "d_2g_ppl                 1163 non-null float64\n",
      "d_3g_ppl                 1163 non-null float64\n",
      "z_mlu_sli                1163 non-null float64\n",
      "z_mlu_td                 1163 non-null float64\n",
      "z_word_errors_sli        1163 non-null float64\n",
      "z_word_errors_td         1163 non-null float64\n",
      "z_r_2_i_verbs_sli        1163 non-null float64\n",
      "z_r_2_i_verbs_td         1163 non-null float64\n",
      "z_utts_sli               1163 non-null float64\n",
      "z_utts_td                1163 non-null float64\n",
      "total_syl                1163 non-null int64\n",
      "average_syl              1163 non-null float64\n",
      "mlu_words                1163 non-null float64\n",
      "mlu_morphemes            1163 non-null float64\n",
      "mlu100_utts              1163 non-null int64\n",
      "verb_utt                 1163 non-null float64\n",
      "dss                      1163 non-null float64\n",
      "ipsyn_total              1163 non-null int64\n",
      "present_progressive      1163 non-null int64\n",
      "propositions_in          1163 non-null int64\n",
      "propositions_on          1163 non-null int64\n",
      "plural_s                 1163 non-null int64\n",
      "irregular_past_tense     1163 non-null int64\n",
      "possessive_s             1163 non-null int64\n",
      "uncontractible_copula    1163 non-null int64\n",
      "articles                 1163 non-null int64\n",
      "regular_past_ed          1163 non-null int64\n",
      "regular_3rd_person_s     1163 non-null int64\n",
      "irregular_3rd_person     1163 non-null int64\n",
      "uncontractible_aux       1163 non-null int64\n",
      "contractible_copula      1163 non-null int64\n",
      "contractible_aux         1163 non-null int64\n",
      "word_errors              1163 non-null int64\n",
      "f_k                      1163 non-null float64\n",
      "n_v                      1163 non-null int64\n",
      "n_aux                    1163 non-null int64\n",
      "n_3s_v                   1163 non-null int64\n",
      "det_n_pl                 1163 non-null int64\n",
      "det_pl_n                 1163 non-null int64\n",
      "pro_aux                  1163 non-null int64\n",
      "pro_3s_v                 1163 non-null int64\n",
      "total_error              1163 non-null int64\n",
      "dtypes: float64(23), int64(36)\n",
      "memory usage: 545.2 KB\n"
     ]
    }
   ],
   "source": [
    "dfx_imputed = impute_missing(dfx,variable_type)\n",
    "dfx_imputed.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_binary_and_category(x,variable_type):\n",
    "    \"\"\"\n",
    "    convert binary to +-1, category to one hot; remain continuous.\n",
    "    \"\"\"    \n",
    "    onehot_encoder = OneHotEncoder(sparse=False,categories='auto')\n",
    "\n",
    "    # create 2 initial columns\n",
    "    x_new = np.zeros((x.shape[0],2))\n",
    "\n",
    "    for i,i_type in enumerate(variable_type):\n",
    "        if i_type == 1: # binary\n",
    "            unique_value = np.unique(x[:,i])\n",
    "            x1 = np.array([-1. if value == unique_value[0] else 1. for value in x[:,i]])        \n",
    "            x_new = np.hstack((x_new,x1[:,np.newaxis]))\n",
    "\n",
    "        elif i_type == 2: # category\n",
    "            x1 = onehot_encoder.fit_transform(x[:,i].reshape(-1,1))\n",
    "            x_new = np.hstack((x_new,x1))\n",
    "            \n",
    "        else: # continuous      \n",
    "            x_new = np.hstack((x_new,x[:,i][:,np.newaxis]))      \n",
    "\n",
    "    # drop the 2 initial column\n",
    "    x_new = x_new[:,2:]\n",
    "    \n",
    "    return x_new.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1163, 63)\n",
      "[[165.          13.75       287.         ...   0.           1.\n",
      "   12.        ]\n",
      " [172.          14.33333333 368.         ...   0.           0.\n",
      "    9.        ]\n",
      " [160.          13.33333333 266.         ...   0.           0.\n",
      "    6.        ]\n",
      " ...\n",
      " [119.           9.91666667 337.         ...   0.           4.\n",
      "    9.        ]\n",
      " [112.           9.33333333 511.         ...   0.           5.\n",
      "   15.        ]\n",
      " [108.           9.         495.         ...   0.           4.\n",
      "   12.        ]]\n"
     ]
    }
   ],
   "source": [
    "# convert x\n",
    "x = np.array(dfx_imputed)\n",
    "x_new = convert_binary_and_category(x,variable_type)\n",
    "\n",
    "print(x_new.shape)\n",
    "print(x_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([896, 267]))\n"
     ]
    }
   ],
   "source": [
    "y = np.array(dfy)\n",
    "#print(np.unique(y,return_counts=True))\n",
    "\n",
    "# convert taget to 0 and 1\n",
    "y_new = y\n",
    "#y_new = np.ones(y.shape[0])\n",
    "#y_new[y =='No'] = 0\n",
    "\n",
    "print(np.unique(y_new,return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine X and y and save to a file\n",
    "xy_new = np.hstack((x_new,y_new[:,np.newaxis]))\n",
    "np.savetxt('data_processed.dat',xy_new,fmt='%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
