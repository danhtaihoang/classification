{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>m32</th>\n",
       "      <th>m33_1</th>\n",
       "      <th>PE</th>\n",
       "      <th>m33_2</th>\n",
       "      <th>m34</th>\n",
       "      <th>m35</th>\n",
       "      <th>m35_1_2</th>\n",
       "      <th>m35_2_2</th>\n",
       "      <th>m35_1_3</th>\n",
       "      <th>...</th>\n",
       "      <th>IPE5</th>\n",
       "      <th>IPE6</th>\n",
       "      <th>IPE7</th>\n",
       "      <th>IPE8</th>\n",
       "      <th>IPE9</th>\n",
       "      <th>IPE10</th>\n",
       "      <th>Age_Categ</th>\n",
       "      <th>Age_recode_2</th>\n",
       "      <th>IIEF5_Categ</th>\n",
       "      <th>IIEF_Y_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sex  m32  m33_1   PE  m33_2  m34  m35  m35_1_2  m35_2_2  m35_1_3  ...  \\\n",
       "0    1    1    1.0  1.0    1.0    1    2      1.0     11.0    999.0  ...   \n",
       "1    1  999    NaN  NaN    NaN    5    1      NaN      NaN      NaN  ...   \n",
       "2    1    2    1.0  1.0    1.0    1    1      NaN      NaN      NaN  ...   \n",
       "3    1    5    2.0  2.0    3.0    2    1      NaN      NaN      NaN  ...   \n",
       "4    1   60    2.0  2.0   45.0    5    1      NaN      NaN      NaN  ...   \n",
       "\n",
       "   IPE5  IPE6  IPE7  IPE8  IPE9  IPE10  Age_Categ  Age_recode_2  IIEF5_Categ  \\\n",
       "0   NaN   5.0   5.0   NaN   0.0    0.0        NaN           NaN          NaN   \n",
       "1   NaN   2.0   1.0   NaN   0.0    0.0        1.0           1.0          NaN   \n",
       "2   NaN   5.0   5.0   NaN   0.0    0.0        NaN           NaN          NaN   \n",
       "3   NaN   1.0   1.0   NaN   0.0    0.0        3.0           3.0          NaN   \n",
       "4   4.0   3.0   5.0   5.0   4.0    3.0        1.0           1.0          2.0   \n",
       "\n",
       "   IIEF_Y_N  \n",
       "0       NaN  \n",
       "1       NaN  \n",
       "2       NaN  \n",
       "3       NaN  \n",
       "4       1.0  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"ef.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1004 entries, 0 to 1003\n",
      "Data columns (total 55 columns):\n",
      "sex                    1004 non-null int64\n",
      "m32                    1004 non-null int64\n",
      "m33_1                  920 non-null float64\n",
      "PE                     816 non-null float64\n",
      "m33_2                  816 non-null float64\n",
      "m34                    1004 non-null int64\n",
      "m35                    1004 non-null int64\n",
      "m35_1_2                126 non-null float64\n",
      "m35_2_2                43 non-null float64\n",
      "m35_1_3                126 non-null float64\n",
      "m35_2_3                46 non-null float64\n",
      "m36_3                  133 non-null float64\n",
      "m36_4                  133 non-null float64\n",
      "m42                    1004 non-null int64\n",
      "m43                    1004 non-null int64\n",
      "m44                    1004 non-null int64\n",
      "m45                    1004 non-null int64\n",
      "m46                    1004 non-null int64\n",
      "m47                    1004 non-null int64\n",
      "m48                    1004 non-null int64\n",
      "m49                    1004 non-null int64\n",
      "m50                    1004 non-null int64\n",
      "m51                    1004 non-null int64\n",
      "m52                    1004 non-null int64\n",
      "m53                    1004 non-null int64\n",
      "m54                    1004 non-null int64\n",
      "m55                    1004 non-null int64\n",
      "AGE                    960 non-null float64\n",
      "nic                    0 non-null float64\n",
      "vek_kat                1004 non-null int64\n",
      "iief                   930 non-null float64\n",
      "q1                     969 non-null float64\n",
      "q2                     972 non-null float64\n",
      "q3                     959 non-null float64\n",
      "q4                     956 non-null float64\n",
      "q5                     953 non-null float64\n",
      "iief5                  766 non-null float64\n",
      "IIEF5categories        947 non-null float64\n",
      "Control                664 non-null float64\n",
      "Sexual_Satisfaction    664 non-null float64\n",
      "Distress               1004 non-null int64\n",
      "IPE1                   674 non-null float64\n",
      "IPE2                   675 non-null float64\n",
      "IPE3                   677 non-null float64\n",
      "IPE4                   669 non-null float64\n",
      "IPE5                   674 non-null float64\n",
      "IPE6                   920 non-null float64\n",
      "IPE7                   810 non-null float64\n",
      "IPE8                   678 non-null float64\n",
      "IPE9                   967 non-null float64\n",
      "IPE10                  964 non-null float64\n",
      "Age_Categ              960 non-null float64\n",
      "Age_recode_2           960 non-null float64\n",
      "IIEF5_Categ            766 non-null float64\n",
      "IIEF_Y_N               766 non-null float64\n",
      "dtypes: float64(35), int64(20)\n",
      "memory usage: 431.5 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'IIEF_Y_N'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace empty or errors by np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace empty/erros by np.nan\n",
    "df = df.replace(r'^\\s+$', np.nan, regex=True)\n",
    "df = df.replace('\\t','',regex=True)\n",
    "df = df.replace(' ','',regex=True)\n",
    "df = df.replace('\\?',np.nan,regex=True)\n",
    "df = df.replace('\\<',np.nan,regex=True)\n",
    "df = df.replace('#NULL!',np.nan,regex=True)\n",
    "#df = df.replace('99',np.nan,regex=True)\n",
    "#df = df.replace(99,np.nan,regex=True)\n",
    "#df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>m32</th>\n",
       "      <th>m33_1</th>\n",
       "      <th>PE</th>\n",
       "      <th>m33_2</th>\n",
       "      <th>m34</th>\n",
       "      <th>m35</th>\n",
       "      <th>m35_1_2</th>\n",
       "      <th>m35_2_2</th>\n",
       "      <th>m35_1_3</th>\n",
       "      <th>...</th>\n",
       "      <th>IPE5</th>\n",
       "      <th>IPE6</th>\n",
       "      <th>IPE7</th>\n",
       "      <th>IPE8</th>\n",
       "      <th>IPE9</th>\n",
       "      <th>IPE10</th>\n",
       "      <th>Age_Categ</th>\n",
       "      <th>Age_recode_2</th>\n",
       "      <th>IIEF5_Categ</th>\n",
       "      <th>IIEF_Y_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sex  m32  m33_1   PE  m33_2  m34  m35  m35_1_2  m35_2_2  m35_1_3  ...  \\\n",
       "0    1    1    1.0  1.0    1.0    1    2      1.0     11.0    999.0  ...   \n",
       "1    1  999    NaN  NaN    NaN    5    1      NaN      NaN      NaN  ...   \n",
       "2    1    2    1.0  1.0    1.0    1    1      NaN      NaN      NaN  ...   \n",
       "3    1    5    2.0  2.0    3.0    2    1      NaN      NaN      NaN  ...   \n",
       "4    1   60    2.0  2.0   45.0    5    1      NaN      NaN      NaN  ...   \n",
       "\n",
       "   IPE5  IPE6  IPE7  IPE8  IPE9  IPE10  Age_Categ  Age_recode_2  IIEF5_Categ  \\\n",
       "0   NaN   5.0   5.0   NaN   0.0    0.0        NaN           NaN          NaN   \n",
       "1   NaN   2.0   1.0   NaN   0.0    0.0        1.0           1.0          NaN   \n",
       "2   NaN   5.0   5.0   NaN   0.0    0.0        NaN           NaN          NaN   \n",
       "3   NaN   1.0   1.0   NaN   0.0    0.0        3.0           3.0          NaN   \n",
       "4   4.0   3.0   5.0   5.0   4.0    3.0        1.0           1.0          2.0   \n",
       "\n",
       "   IIEF_Y_N  \n",
       "0       NaN  \n",
       "1       NaN  \n",
       "2       NaN  \n",
       "3       NaN  \n",
       "4       1.0  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the column outliers as it is unrelated to the dependent variable\n",
    "outliers = []\n",
    "df = df.drop(outliers,axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove bad columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_bad_columns(df,bad_column_threshold):\n",
    "    # find bad columns having too many missing values\n",
    "    n_null = np.array(df.isnull().sum(axis=0))\n",
    "    bad_col = np.array([]).astype(int)\n",
    "    for i in range(len(n_null)):\n",
    "        if n_null[i] >= bad_column_threshold:\n",
    "            bad_col = np.append(bad_col,i)\n",
    "\n",
    "    #print(bad_col)\n",
    "    print('number of bad columns:',len(bad_col))\n",
    "\n",
    "    # delete bad columns\n",
    "    df = df.drop(df.columns[bad_col],axis=1)\n",
    "    #df.info()\n",
    "    return df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of bad columns: 7\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1004 entries, 0 to 1003\n",
      "Data columns (total 48 columns):\n",
      "sex                    1004 non-null int64\n",
      "m32                    1004 non-null int64\n",
      "m33_1                  920 non-null float64\n",
      "PE                     816 non-null float64\n",
      "m33_2                  816 non-null float64\n",
      "m34                    1004 non-null int64\n",
      "m35                    1004 non-null int64\n",
      "m42                    1004 non-null int64\n",
      "m43                    1004 non-null int64\n",
      "m44                    1004 non-null int64\n",
      "m45                    1004 non-null int64\n",
      "m46                    1004 non-null int64\n",
      "m47                    1004 non-null int64\n",
      "m48                    1004 non-null int64\n",
      "m49                    1004 non-null int64\n",
      "m50                    1004 non-null int64\n",
      "m51                    1004 non-null int64\n",
      "m52                    1004 non-null int64\n",
      "m53                    1004 non-null int64\n",
      "m54                    1004 non-null int64\n",
      "m55                    1004 non-null int64\n",
      "AGE                    960 non-null float64\n",
      "vek_kat                1004 non-null int64\n",
      "iief                   930 non-null float64\n",
      "q1                     969 non-null float64\n",
      "q2                     972 non-null float64\n",
      "q3                     959 non-null float64\n",
      "q4                     956 non-null float64\n",
      "q5                     953 non-null float64\n",
      "iief5                  766 non-null float64\n",
      "IIEF5categories        947 non-null float64\n",
      "Control                664 non-null float64\n",
      "Sexual_Satisfaction    664 non-null float64\n",
      "Distress               1004 non-null int64\n",
      "IPE1                   674 non-null float64\n",
      "IPE2                   675 non-null float64\n",
      "IPE3                   677 non-null float64\n",
      "IPE4                   669 non-null float64\n",
      "IPE5                   674 non-null float64\n",
      "IPE6                   920 non-null float64\n",
      "IPE7                   810 non-null float64\n",
      "IPE8                   678 non-null float64\n",
      "IPE9                   967 non-null float64\n",
      "IPE10                  964 non-null float64\n",
      "Age_Categ              960 non-null float64\n",
      "Age_recode_2           960 non-null float64\n",
      "IIEF5_Categ            766 non-null float64\n",
      "IIEF_Y_N               766 non-null float64\n",
      "dtypes: float64(28), int64(20)\n",
      "memory usage: 376.6 KB\n"
     ]
    }
   ],
   "source": [
    "df = remove_bad_columns(df,400)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove bad rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Find rows where target is missing\n",
    "def find_missing_target_rows(df,target):\n",
    "    # find rows where target is missing\n",
    "    missing_row = df[target].isnull()\n",
    "    print('Number of rows where target are missing:')\n",
    "    print(sum(missing_row))\n",
    "\n",
    "    #df = df[~missing_row]\n",
    "    missing_row_indices = np.array([t for t in range(df.shape[0]) if missing_row[t]])\n",
    "    \n",
    "    return missing_row_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows where target are missing:\n",
      "238\n"
     ]
    }
   ],
   "source": [
    "missing_target_rows = find_missing_target_rows(df,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find bad rows which contain too many missing values, then remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_bad_rows(df,bad_row_threshold):   \n",
    "    # find bad rows having too many missing values\n",
    "    n_null = np.array(df.isnull().sum(axis=1))\n",
    "    bad_row = np.array([]).astype(int)\n",
    "    for t in range(len(n_null)):\n",
    "        if n_null[t] >= bad_row_threshold:\n",
    "            bad_row = np.append(bad_row,t)\n",
    "\n",
    "    #print(bad_row)\n",
    "    print('number of bad rows:',len(bad_row))\n",
    "\n",
    "    # delete bad rows\n",
    "    #df = df.drop(bad_row)\n",
    "    #df.info()\n",
    "    return bad_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of bad rows: 339\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1004 entries, 0 to 1003\n",
      "Data columns (total 48 columns):\n",
      "sex                    1004 non-null int64\n",
      "m32                    1004 non-null int64\n",
      "m33_1                  920 non-null float64\n",
      "PE                     816 non-null float64\n",
      "m33_2                  816 non-null float64\n",
      "m34                    1004 non-null int64\n",
      "m35                    1004 non-null int64\n",
      "m42                    1004 non-null int64\n",
      "m43                    1004 non-null int64\n",
      "m44                    1004 non-null int64\n",
      "m45                    1004 non-null int64\n",
      "m46                    1004 non-null int64\n",
      "m47                    1004 non-null int64\n",
      "m48                    1004 non-null int64\n",
      "m49                    1004 non-null int64\n",
      "m50                    1004 non-null int64\n",
      "m51                    1004 non-null int64\n",
      "m52                    1004 non-null int64\n",
      "m53                    1004 non-null int64\n",
      "m54                    1004 non-null int64\n",
      "m55                    1004 non-null int64\n",
      "AGE                    960 non-null float64\n",
      "vek_kat                1004 non-null int64\n",
      "iief                   930 non-null float64\n",
      "q1                     969 non-null float64\n",
      "q2                     972 non-null float64\n",
      "q3                     959 non-null float64\n",
      "q4                     956 non-null float64\n",
      "q5                     953 non-null float64\n",
      "iief5                  766 non-null float64\n",
      "IIEF5categories        947 non-null float64\n",
      "Control                664 non-null float64\n",
      "Sexual_Satisfaction    664 non-null float64\n",
      "Distress               1004 non-null int64\n",
      "IPE1                   674 non-null float64\n",
      "IPE2                   675 non-null float64\n",
      "IPE3                   677 non-null float64\n",
      "IPE4                   669 non-null float64\n",
      "IPE5                   674 non-null float64\n",
      "IPE6                   920 non-null float64\n",
      "IPE7                   810 non-null float64\n",
      "IPE8                   678 non-null float64\n",
      "IPE9                   967 non-null float64\n",
      "IPE10                  964 non-null float64\n",
      "Age_Categ              960 non-null float64\n",
      "Age_recode_2           960 non-null float64\n",
      "IIEF5_Categ            766 non-null float64\n",
      "IIEF_Y_N               766 non-null float64\n",
      "dtypes: float64(28), int64(20)\n",
      "memory usage: 376.6 KB\n"
     ]
    }
   ],
   "source": [
    "bad_rows = find_bad_rows(df,5)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows need to delete: 339\n"
     ]
    }
   ],
   "source": [
    "del_rows = np.union1d(missing_target_rows,bad_rows)\n",
    "print('number of rows need to delete:',len(del_rows))\n",
    "\n",
    "df = df.drop(del_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate target and attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx = df.drop(target,axis=1)\n",
    "dfy = df[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find variable type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of uniques of each variable:\n",
      "[ 1 29  3  2 25  7  3  5  6  5  6  5  5  6  6  6  6  5  5  5  5 60  6 18\n",
      "  5  5  5  5  5 15  2 16 17  9  5  5  5  5  5  5  5  5  5  5  8  7  4]\n"
     ]
    }
   ],
   "source": [
    "# number of uniques of each column (excluding NaN)\n",
    "nu = np.array([len(pd.unique(dfx[col].dropna())) for col in dfx.columns])\n",
    "print('number of uniques of each variable:')\n",
    "print(nu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def define_variable_type(df,nu):\n",
    "    i_binary = [] ; i_category = [] ; i_continuous = []\n",
    "    for i in range(len(nu)):\n",
    "        if nu[i] == 2: # binary \n",
    "            i_binary.append(i)\n",
    "        elif nu[i] < 5: # !!!! NOTE: this is not always correct, depending on data\n",
    "            i_category.append(i)\n",
    "        else:\n",
    "            i_continuous.append(i)\n",
    "\n",
    "    print('i_binary:',i_binary)\n",
    "    print('i_category:',i_category)   \n",
    "    #i_binary, i_category, i_continuous\n",
    "    \n",
    "    variable_type  = np.ones(len(nu))  # binary\n",
    "    variable_type[i_category] = 2   # categorical\n",
    "    variable_type[i_continuous] = 3 # continuous\n",
    "\n",
    "    return variable_type #,i_binary,i_category,i_continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i_binary: [3, 30]\n",
      "i_category: [0, 2, 6, 46]\n",
      "variable type: [2. 3. 2. 1. 3. 3. 2. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 1. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 2.]\n"
     ]
    }
   ],
   "source": [
    "variable_type = define_variable_type(dfx,nu)\n",
    "print('variable type:',variable_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute missing values of attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing(df,variable_type):\n",
    "    # impute binary and categorical variables by the most frequency (in each column)\n",
    "    # continuous variable by median\n",
    "    # input: df: pandas data frame, variable_type: list\n",
    "    # output: df2: pandas data frame\n",
    "    df2 = df.copy()\n",
    "    for i,col in enumerate(df.columns):\n",
    "        if variable_type[i] < 3: # binary or caterogy\n",
    "            df2[col] = df[col].fillna(df[col].mode().iloc[0])\n",
    "        else: # continuous\n",
    "            df2[col] = df[col].fillna(df[col].median())    \n",
    "    return df2       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 665 entries, 4 to 1002\n",
      "Data columns (total 47 columns):\n",
      "sex                    665 non-null int64\n",
      "m32                    665 non-null int64\n",
      "m33_1                  665 non-null float64\n",
      "PE                     665 non-null float64\n",
      "m33_2                  665 non-null float64\n",
      "m34                    665 non-null int64\n",
      "m35                    665 non-null int64\n",
      "m42                    665 non-null int64\n",
      "m43                    665 non-null int64\n",
      "m44                    665 non-null int64\n",
      "m45                    665 non-null int64\n",
      "m46                    665 non-null int64\n",
      "m47                    665 non-null int64\n",
      "m48                    665 non-null int64\n",
      "m49                    665 non-null int64\n",
      "m50                    665 non-null int64\n",
      "m51                    665 non-null int64\n",
      "m52                    665 non-null int64\n",
      "m53                    665 non-null int64\n",
      "m54                    665 non-null int64\n",
      "m55                    665 non-null int64\n",
      "AGE                    665 non-null float64\n",
      "vek_kat                665 non-null int64\n",
      "iief                   665 non-null float64\n",
      "q1                     665 non-null float64\n",
      "q2                     665 non-null float64\n",
      "q3                     665 non-null float64\n",
      "q4                     665 non-null float64\n",
      "q5                     665 non-null float64\n",
      "iief5                  665 non-null float64\n",
      "IIEF5categories        665 non-null float64\n",
      "Control                665 non-null float64\n",
      "Sexual_Satisfaction    665 non-null float64\n",
      "Distress               665 non-null int64\n",
      "IPE1                   665 non-null float64\n",
      "IPE2                   665 non-null float64\n",
      "IPE3                   665 non-null float64\n",
      "IPE4                   665 non-null float64\n",
      "IPE5                   665 non-null float64\n",
      "IPE6                   665 non-null float64\n",
      "IPE7                   665 non-null float64\n",
      "IPE8                   665 non-null float64\n",
      "IPE9                   665 non-null float64\n",
      "IPE10                  665 non-null float64\n",
      "Age_Categ              665 non-null float64\n",
      "Age_recode_2           665 non-null float64\n",
      "IIEF5_Categ            665 non-null float64\n",
      "dtypes: float64(27), int64(20)\n",
      "memory usage: 249.4 KB\n"
     ]
    }
   ],
   "source": [
    "dfx_imputed = impute_missing(dfx,variable_type)\n",
    "dfx_imputed.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_binary_and_category(x,variable_type):\n",
    "    \"\"\"\n",
    "    convert binary to +-1, category to one hot; remain continuous.\n",
    "    \"\"\"    \n",
    "    onehot_encoder = OneHotEncoder(sparse=False,categories='auto')\n",
    "\n",
    "    # create 2 initial columns\n",
    "    x_new = np.zeros((x.shape[0],2))\n",
    "\n",
    "    for i,i_type in enumerate(variable_type):\n",
    "        if i_type == 1: # binary\n",
    "            unique_value = np.unique(x[:,i])\n",
    "            x1 = np.array([-1. if value == unique_value[0] else 1. for value in x[:,i]])        \n",
    "            x_new = np.hstack((x_new,x1[:,np.newaxis]))\n",
    "\n",
    "        elif i_type == 2: # category\n",
    "            x1 = onehot_encoder.fit_transform(x[:,i].reshape(-1,1))\n",
    "            x_new = np.hstack((x_new,x1))\n",
    "            \n",
    "        else: # continuous      \n",
    "            x_new = np.hstack((x_new,x[:,i][:,np.newaxis]))      \n",
    "\n",
    "    # drop the 2 initial column\n",
    "    x_new = x_new[:,2:]\n",
    "    \n",
    "    return x_new.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(665, 54)\n",
      "[[ 1. 60.  0. ...  1.  0.  0.]\n",
      " [ 1.  5.  0. ...  1.  0.  0.]\n",
      " [ 1. 10.  0. ...  1.  0.  0.]\n",
      " ...\n",
      " [ 1. 45.  0. ...  1.  0.  0.]\n",
      " [ 1. 30.  0. ...  1.  0.  0.]\n",
      " [ 1. 10.  0. ...  1.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# convert x\n",
    "x = np.array(dfx_imputed)\n",
    "x_new = convert_binary_and_category(x,variable_type)\n",
    "\n",
    "print(x_new.shape)\n",
    "print(x_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0., 1.]), array([ 93, 572]))\n"
     ]
    }
   ],
   "source": [
    "y = np.array(dfy)\n",
    "#print(np.unique(y,return_counts=True))\n",
    "\n",
    "# convert taget to 0 and 1\n",
    "#y_new = y\n",
    "y_new = np.ones(y.shape[0])\n",
    "y_new[y == 2] = 0\n",
    "\n",
    "print(np.unique(y_new,return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine X and y and save to a file\n",
    "xy_new = np.hstack((x_new,y_new[:,np.newaxis]))\n",
    "np.savetxt('data_processed.dat',xy_new,fmt='%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
