{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>school_year</th>\n",
       "      <th>semester</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>phq1</th>\n",
       "      <th>phq2</th>\n",
       "      <th>phq3</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 245</th>\n",
       "      <th>Unnamed: 246</th>\n",
       "      <th>Unnamed: 247</th>\n",
       "      <th>Unnamed: 248</th>\n",
       "      <th>Unnamed: 249</th>\n",
       "      <th>Unnamed: 250</th>\n",
       "      <th>Unnamed: 251</th>\n",
       "      <th>Unnamed: 252</th>\n",
       "      <th>Unnamed: 253</th>\n",
       "      <th>Unnamed: 254</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>m</td>\n",
       "      <td>1.50</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>m</td>\n",
       "      <td>1.68</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>m</td>\n",
       "      <td>1.74</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>f</td>\n",
       "      <td>1.68</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>m</td>\n",
       "      <td>1.80</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 255 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  school_year  semester   age gender  height  weight  phq1  phq2  phq3  \\\n",
       "0  A1            1         1  19.0      m    1.50    75.0   2.0   1.0   1.0   \n",
       "1  B2            1         1  18.0      m    1.68    56.0   2.0   0.0   1.0   \n",
       "2  C3            1         1  19.0      m    1.74    76.0   1.0   1.0   0.0   \n",
       "3  D4            1         1  18.0      f    1.68    67.0   2.0   2.0   3.0   \n",
       "4  E5            1         1  18.0      m    1.80    83.0   0.0   1.0   1.0   \n",
       "\n",
       "   ...  Unnamed: 245  Unnamed: 246  Unnamed: 247  Unnamed: 248  Unnamed: 249  \\\n",
       "0  ...           NaN           NaN           NaN           NaN           NaN   \n",
       "1  ...           NaN           NaN           NaN           NaN           NaN   \n",
       "2  ...           NaN           NaN           NaN           NaN           NaN   \n",
       "3  ...           NaN           NaN           NaN           NaN           NaN   \n",
       "4  ...           NaN           NaN           NaN           NaN           NaN   \n",
       "\n",
       "   Unnamed: 250  Unnamed: 251  Unnamed: 252  Unnamed: 253  Unnamed: 254  \n",
       "0           NaN           NaN           NaN           NaN           NaN  \n",
       "1           NaN           NaN           NaN           NaN           NaN  \n",
       "2           NaN           NaN           NaN           NaN           NaN  \n",
       "3           NaN           NaN           NaN           NaN           NaN  \n",
       "4           NaN           NaN           NaN           NaN           NaN  \n",
       "\n",
       "[5 rows x 255 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"mental.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 776 entries, 0 to 775\n",
      "Columns: 255 entries, id to Unnamed: 254\n",
      "dtypes: float64(246), int64(2), object(7)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'thoughts_of_dropping_out'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace empty or errors by np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace empty/erros by np.nan\n",
    "df = df.replace(r'^\\s+$', np.nan, regex=True)\n",
    "df = df.replace('\\t','',regex=True)\n",
    "df = df.replace(' ','',regex=True)\n",
    "df = df.replace('\\?',np.nan,regex=True)\n",
    "df = df.replace('\\<',np.nan,regex=True)\n",
    "df = df.replace('#NULL!',np.nan,regex=True)\n",
    "\n",
    "#df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_year</th>\n",
       "      <th>semester</th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>phq1</th>\n",
       "      <th>phq2</th>\n",
       "      <th>phq3</th>\n",
       "      <th>phq4</th>\n",
       "      <th>phq5</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 245</th>\n",
       "      <th>Unnamed: 246</th>\n",
       "      <th>Unnamed: 247</th>\n",
       "      <th>Unnamed: 248</th>\n",
       "      <th>Unnamed: 249</th>\n",
       "      <th>Unnamed: 250</th>\n",
       "      <th>Unnamed: 251</th>\n",
       "      <th>Unnamed: 252</th>\n",
       "      <th>Unnamed: 253</th>\n",
       "      <th>Unnamed: 254</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.74</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 248 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   school_year  semester   age  height  weight  phq1  phq2  phq3  phq4  phq5  \\\n",
       "0            1         1  19.0    1.50    75.0   2.0   1.0   1.0   1.0   2.0   \n",
       "1            1         1  18.0    1.68    56.0   2.0   0.0   1.0   2.0   1.0   \n",
       "2            1         1  19.0    1.74    76.0   1.0   1.0   0.0   3.0   1.0   \n",
       "3            1         1  18.0    1.68    67.0   2.0   2.0   3.0   3.0   3.0   \n",
       "4            1         1  18.0    1.80    83.0   0.0   1.0   1.0   2.0   1.0   \n",
       "\n",
       "   ...  Unnamed: 245  Unnamed: 246  Unnamed: 247  Unnamed: 248  Unnamed: 249  \\\n",
       "0  ...           NaN           NaN           NaN           NaN           NaN   \n",
       "1  ...           NaN           NaN           NaN           NaN           NaN   \n",
       "2  ...           NaN           NaN           NaN           NaN           NaN   \n",
       "3  ...           NaN           NaN           NaN           NaN           NaN   \n",
       "4  ...           NaN           NaN           NaN           NaN           NaN   \n",
       "\n",
       "   Unnamed: 250  Unnamed: 251  Unnamed: 252  Unnamed: 253  Unnamed: 254  \n",
       "0           NaN           NaN           NaN           NaN           NaN  \n",
       "1           NaN           NaN           NaN           NaN           NaN  \n",
       "2           NaN           NaN           NaN           NaN           NaN  \n",
       "3           NaN           NaN           NaN           NaN           NaN  \n",
       "4           NaN           NaN           NaN           NaN           NaN  \n",
       "\n",
       "[5 rows x 248 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the column outliers as it is unrelated to the dependent variable\n",
    "outliers = ['id','gender','bed_time','wake_up_time','reported_sleep_hours','nap_duration','weekly_study_hours']\n",
    "df = df.drop(outliers,axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove bad columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_bad_columns(df,bad_column_threshold):\n",
    "    # find bad columns having too many missing values\n",
    "    n_null = np.array(df.isnull().sum(axis=0))\n",
    "    bad_col = np.array([]).astype(int)\n",
    "    for i in range(len(n_null)):\n",
    "        if n_null[i] >= bad_column_threshold:\n",
    "            bad_col = np.append(bad_col,i)\n",
    "\n",
    "    #print(bad_col)\n",
    "    print('number of bad columns:',len(bad_col))\n",
    "\n",
    "    # delete bad columns\n",
    "    df = df.drop(df.columns[bad_col],axis=1)\n",
    "    #df.info()\n",
    "    return df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of bad columns: 213\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 776 entries, 0 to 775\n",
      "Data columns (total 35 columns):\n",
      "school_year                      776 non-null int64\n",
      "semester                         776 non-null int64\n",
      "age                              775 non-null float64\n",
      "height                           770 non-null float64\n",
      "weight                           771 non-null float64\n",
      "phq1                             774 non-null float64\n",
      "phq2                             774 non-null float64\n",
      "phq3                             774 non-null float64\n",
      "phq4                             774 non-null float64\n",
      "phq5                             771 non-null float64\n",
      "phq6                             774 non-null float64\n",
      "phq7                             774 non-null float64\n",
      "phq8                             774 non-null float64\n",
      "phq9                             774 non-null float64\n",
      "thoughts_of_dropping_out         771 non-null float64\n",
      "previous_depression_diagnosis    774 non-null float64\n",
      "previous_depression_treatment    771 non-null float64\n",
      "gad1                             772 non-null float64\n",
      "gad2                             771 non-null float64\n",
      "gad3                             772 non-null float64\n",
      "gad4                             770 non-null float64\n",
      "gad5                             772 non-null float64\n",
      "gad6                             772 non-null float64\n",
      "gad7                             772 non-null float64\n",
      "previous_anxiety_diagnosis       771 non-null float64\n",
      "previous_anxiety_treatment       773 non-null float64\n",
      "epw1                             769 non-null float64\n",
      "epw2                             769 non-null float64\n",
      "epw3                             769 non-null float64\n",
      "epw4                             768 non-null float64\n",
      "epw5                             769 non-null float64\n",
      "epw6                             768 non-null float64\n",
      "epw7                             769 non-null float64\n",
      "epw8                             769 non-null float64\n",
      "times_week_nap                   763 non-null float64\n",
      "dtypes: float64(33), int64(2)\n",
      "memory usage: 212.3 KB\n"
     ]
    }
   ],
   "source": [
    "df = remove_bad_columns(df,16)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove bad rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Find rows where target is missing\n",
    "def find_missing_target_rows(df,target):\n",
    "    # find rows where target is missing\n",
    "    missing_row = df[target].isnull()\n",
    "    print('Number of rows where target are missing:')\n",
    "    print(sum(missing_row))\n",
    "\n",
    "    #df = df[~missing_row]\n",
    "    missing_row_indices = np.array([t for t in range(df.shape[0]) if missing_row[t]])\n",
    "    \n",
    "    return missing_row_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows where target are missing:\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "missing_target_rows = find_missing_target_rows(df,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find bad rows which contain too many missing values, then remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_bad_rows(df,bad_row_threshold):   \n",
    "    # find bad rows having too many missing values\n",
    "    n_null = np.array(df.isnull().sum(axis=1))\n",
    "    bad_row = np.array([]).astype(int)\n",
    "    for t in range(len(n_null)):\n",
    "        if n_null[t] >= bad_row_threshold:\n",
    "            bad_row = np.append(bad_row,t)\n",
    "\n",
    "    #print(bad_row)\n",
    "    print('number of bad rows:',len(bad_row))\n",
    "\n",
    "    # delete bad rows\n",
    "    #df = df.drop(bad_row)\n",
    "    #df.info()\n",
    "    return bad_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of bad rows: 9\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 776 entries, 0 to 775\n",
      "Data columns (total 35 columns):\n",
      "school_year                      776 non-null int64\n",
      "semester                         776 non-null int64\n",
      "age                              775 non-null float64\n",
      "height                           770 non-null float64\n",
      "weight                           771 non-null float64\n",
      "phq1                             774 non-null float64\n",
      "phq2                             774 non-null float64\n",
      "phq3                             774 non-null float64\n",
      "phq4                             774 non-null float64\n",
      "phq5                             771 non-null float64\n",
      "phq6                             774 non-null float64\n",
      "phq7                             774 non-null float64\n",
      "phq8                             774 non-null float64\n",
      "phq9                             774 non-null float64\n",
      "thoughts_of_dropping_out         771 non-null float64\n",
      "previous_depression_diagnosis    774 non-null float64\n",
      "previous_depression_treatment    771 non-null float64\n",
      "gad1                             772 non-null float64\n",
      "gad2                             771 non-null float64\n",
      "gad3                             772 non-null float64\n",
      "gad4                             770 non-null float64\n",
      "gad5                             772 non-null float64\n",
      "gad6                             772 non-null float64\n",
      "gad7                             772 non-null float64\n",
      "previous_anxiety_diagnosis       771 non-null float64\n",
      "previous_anxiety_treatment       773 non-null float64\n",
      "epw1                             769 non-null float64\n",
      "epw2                             769 non-null float64\n",
      "epw3                             769 non-null float64\n",
      "epw4                             768 non-null float64\n",
      "epw5                             769 non-null float64\n",
      "epw6                             768 non-null float64\n",
      "epw7                             769 non-null float64\n",
      "epw8                             769 non-null float64\n",
      "times_week_nap                   763 non-null float64\n",
      "dtypes: float64(33), int64(2)\n",
      "memory usage: 212.3 KB\n"
     ]
    }
   ],
   "source": [
    "bad_rows = find_bad_rows(df,6)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows need to delete: 13\n"
     ]
    }
   ],
   "source": [
    "del_rows = np.union1d(missing_target_rows,bad_rows)\n",
    "print('number of rows need to delete:',len(del_rows))\n",
    "\n",
    "df = df.drop(del_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate target and attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx = df.drop(target,axis=1)\n",
    "dfy = df[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find variable type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of uniques of each variable:\n",
      "[ 4  7 15 47 88  4  4  4  4  4  4  4  4  4  2  2  4  4  4  4  4  4  4  2\n",
      "  2  5  5  5  5  5  5  5  5  5]\n"
     ]
    }
   ],
   "source": [
    "# number of uniques of each column (excluding NaN)\n",
    "nu = np.array([len(pd.unique(dfx[col].dropna())) for col in dfx.columns])\n",
    "print('number of uniques of each variable:')\n",
    "print(nu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def define_variable_type(df,nu):\n",
    "    i_binary = [] ; i_category = [] ; i_continuous = []\n",
    "    for i in range(len(nu)):\n",
    "        if nu[i] == 2: # binary \n",
    "            i_binary.append(i)\n",
    "        elif nu[i] < 5: # !!!! NOTE: this is not always correct, depending on data\n",
    "            i_category.append(i)\n",
    "        else:\n",
    "            i_continuous.append(i)\n",
    "\n",
    "    print('i_binary:',i_binary)\n",
    "    print('i_category:',i_category)   \n",
    "    #i_binary, i_category, i_continuous\n",
    "    \n",
    "    variable_type  = np.ones(len(nu))  # binary\n",
    "    variable_type[i_category] = 2   # categorical\n",
    "    variable_type[i_continuous] = 3 # continuous\n",
    "\n",
    "    return variable_type #,i_binary,i_category,i_continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i_binary: [14, 15, 23, 24]\n",
      "i_category: [0, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22]\n",
      "variable type: [2. 3. 3. 3. 3. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 2. 2. 1.\n",
      " 1. 3. 3. 3. 3. 3. 3. 3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "variable_type = define_variable_type(dfx,nu)\n",
    "print('variable type:',variable_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute missing values of attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing(df,variable_type):\n",
    "    # impute binary and categorical variables by the most frequency (in each column)\n",
    "    # continuous variable by median\n",
    "    # input: df: pandas data frame, variable_type: list\n",
    "    # output: df2: pandas data frame\n",
    "    df2 = df.copy()\n",
    "    for i,col in enumerate(df.columns):\n",
    "        if variable_type[i] < 3: # binary or caterogy\n",
    "            df2[col] = df[col].fillna(df[col].mode().iloc[0])\n",
    "        else: # continuous\n",
    "            df2[col] = df[col].fillna(df[col].median())    \n",
    "    return df2       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 763 entries, 0 to 775\n",
      "Data columns (total 34 columns):\n",
      "school_year                      763 non-null int64\n",
      "semester                         763 non-null int64\n",
      "age                              763 non-null float64\n",
      "height                           763 non-null float64\n",
      "weight                           763 non-null float64\n",
      "phq1                             763 non-null float64\n",
      "phq2                             763 non-null float64\n",
      "phq3                             763 non-null float64\n",
      "phq4                             763 non-null float64\n",
      "phq5                             763 non-null float64\n",
      "phq6                             763 non-null float64\n",
      "phq7                             763 non-null float64\n",
      "phq8                             763 non-null float64\n",
      "phq9                             763 non-null float64\n",
      "previous_depression_diagnosis    763 non-null float64\n",
      "previous_depression_treatment    763 non-null float64\n",
      "gad1                             763 non-null float64\n",
      "gad2                             763 non-null float64\n",
      "gad3                             763 non-null float64\n",
      "gad4                             763 non-null float64\n",
      "gad5                             763 non-null float64\n",
      "gad6                             763 non-null float64\n",
      "gad7                             763 non-null float64\n",
      "previous_anxiety_diagnosis       763 non-null float64\n",
      "previous_anxiety_treatment       763 non-null float64\n",
      "epw1                             763 non-null float64\n",
      "epw2                             763 non-null float64\n",
      "epw3                             763 non-null float64\n",
      "epw4                             763 non-null float64\n",
      "epw5                             763 non-null float64\n",
      "epw6                             763 non-null float64\n",
      "epw7                             763 non-null float64\n",
      "epw8                             763 non-null float64\n",
      "times_week_nap                   763 non-null float64\n",
      "dtypes: float64(32), int64(2)\n",
      "memory usage: 208.6 KB\n"
     ]
    }
   ],
   "source": [
    "dfx_imputed = impute_missing(dfx,variable_type)\n",
    "dfx_imputed.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_binary_and_category(x,variable_type):\n",
    "    \"\"\"\n",
    "    convert binary to +-1, category to one hot; remain continuous.\n",
    "    \"\"\"    \n",
    "    onehot_encoder = OneHotEncoder(sparse=False,categories='auto')\n",
    "\n",
    "    # create 2 initial columns\n",
    "    x_new = np.zeros((x.shape[0],2))\n",
    "\n",
    "    for i,i_type in enumerate(variable_type):\n",
    "        if i_type == 1: # binary\n",
    "            unique_value = np.unique(x[:,i])\n",
    "            x1 = np.array([-1. if value == unique_value[0] else 1. for value in x[:,i]])        \n",
    "            x_new = np.hstack((x_new,x1[:,np.newaxis]))\n",
    "\n",
    "        elif i_type == 2: # category\n",
    "            x1 = onehot_encoder.fit_transform(x[:,i].reshape(-1,1))\n",
    "            x_new = np.hstack((x_new,x1))\n",
    "            \n",
    "        else: # continuous      \n",
    "            x_new = np.hstack((x_new,x[:,i][:,np.newaxis]))      \n",
    "\n",
    "    # drop the 2 initial column\n",
    "    x_new = x_new[:,2:]\n",
    "    \n",
    "    return x_new.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(763, 85)\n",
      "[[1. 0. 0. ... 1. 1. 1.]\n",
      " [1. 0. 0. ... 2. 2. 2.]\n",
      " [1. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 1.]\n",
      " [0. 0. 0. ... 1. 3. 4.]\n",
      " [0. 0. 0. ... 0. 0. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# convert x\n",
    "x = np.array(dfx_imputed)\n",
    "x_new = convert_binary_and_category(x,variable_type)\n",
    "\n",
    "print(x_new.shape)\n",
    "print(x_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0., 1.]), array([616, 147]))\n"
     ]
    }
   ],
   "source": [
    "y = np.array(dfy)\n",
    "#print(np.unique(y,return_counts=True))\n",
    "\n",
    "# convert taget to 0 and 1\n",
    "y_new = y\n",
    "#y_new = np.ones(y.shape[0])\n",
    "#y_new[y =='No'] = 0\n",
    "\n",
    "print(np.unique(y_new,return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine X and y and save to a file\n",
    "xy_new = np.hstack((x_new,y_new[:,np.newaxis]))\n",
    "np.savetxt('data_processed.dat',xy_new,fmt='%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
