{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,precision_score,\\\n",
    "recall_score,roc_curve,auc\n",
    "\n",
    "import expectation_reflection as ER\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from function import split_train_test,make_data_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, the processed data are imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1paradox']\n"
     ]
    }
   ],
   "source": [
    "data_list = ['1paradox']\n",
    "#data_list = np.loadtxt('data_list.txt',dtype='str')\n",
    "\n",
    "print(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_id):    \n",
    "    data_name = data_list[data_id]\n",
    "    print('data_name:',data_name)\n",
    "    Xy = np.loadtxt('../data/%s/data_processed.dat'%data_name) \n",
    "    X = Xy[:,:-1]\n",
    "    y = Xy[:,-1]\n",
    "\n",
    "    print(np.unique(y,return_counts=True))\n",
    "\n",
    "    X,y = make_data_balance(X,y)\n",
    "\n",
    "    print(np.unique(y,return_counts=True))\n",
    "\n",
    "    X, y = shuffle(X, y, random_state=1)\n",
    "\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.5,random_state = 1)\n",
    "    \n",
    "    sc = MinMaxScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    \n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_name: 1paradox\n",
      "(array([0., 1.]), array([169,  60]))\n",
      "(array([0., 1.]), array([60, 60]))\n"
     ]
    }
   ],
   "source": [
    "data_id = 0\n",
    "X_train,X_test,y_train,y_test = read_data(data_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = LogisticRegression()\n",
    "#model = RandomForestClassifier(random_state = 1)\n",
    "model = SGDClassifier(loss='log',max_iter=1000,tol=0.001)  # 'log' for logistic regression, 'hinge' for SVM\n",
    "\n",
    "# regularization penalty space\n",
    "#penalty = ['l1,l2','elasticnet']\n",
    "penalty = ['elasticnet']\n",
    "\n",
    "# solver\n",
    "#solver=['saga']\n",
    "\n",
    "# regularization hyperparameter space\n",
    "#C = np.logspace(0, 4, 10)\n",
    "alpha = [0.001,0.01,0.1,1.0,10.,100.]\n",
    "\n",
    "# l1_ratio\n",
    "l1_ratio = [0.,0.2,0.4,0.6,0.8,1.0]\n",
    "\n",
    "# Create hyperparameter options\n",
    "#hyperparameters = dict(penalty=penalty,solver=solver,C=C,l1_ratio=l1_ratio)\n",
    "hyper_parameters = dict(penalty=penalty,alpha=alpha,l1_ratio=l1_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grid search using 3-fold cross validation\n",
    "clf = GridSearchCV(model, hyper_parameters, cv=3, iid='deprecated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit grid search\n",
    "best_model = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 0.1\n",
      "Best l1_ratio: 0.8\n"
     ]
    }
   ],
   "source": [
    "# View best hyperparameters\n",
    "#print('Best Penalty:', best_model.best_estimator_.get_params()['penalty'])\n",
    "print('Best alpha:', best_model.best_estimator_.get_params()['alpha'])\n",
    "print('Best l1_ratio:', best_model.best_estimator_.get_params()['l1_ratio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
