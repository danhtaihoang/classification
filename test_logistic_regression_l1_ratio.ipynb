{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'l1_ratio'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f249aa1ff7f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mclf_l2_LR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'l2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'saga'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     clf_en_LR = LogisticRegression(C=C, penalty='elasticnet', solver='saga',\n\u001b[0;32m---> 25\u001b[0;31m                                    l1_ratio=l1_ratio, tol=0.01)\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mclf_l1_LR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mclf_l2_LR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'l1_ratio'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X, y = datasets.load_digits(return_X_y=True)\n",
    "\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "# classify small against large digits\n",
    "y = (y > 4).astype(np.int)\n",
    "\n",
    "l1_ratio = 0.5  # L1 weight in the Elastic-Net regularization\n",
    "\n",
    "fig, axes = plt.subplots(3, 3)\n",
    "\n",
    "# Set regularization parameter\n",
    "for i, (C, axes_row) in enumerate(zip((1, 0.1, 0.01), axes)):\n",
    "    # turn down tolerance for short training time\n",
    "    clf_l1_LR = LogisticRegression(C=C, penalty='l1', tol=0.01, solver='saga')\n",
    "    clf_l2_LR = LogisticRegression(C=C, penalty='l2', tol=0.01, solver='saga')\n",
    "    clf_en_LR = LogisticRegression(C=C, penalty='elasticnet', solver='saga',\n",
    "                                   l1_ratio=l1_ratio, tol=0.01)\n",
    "    clf_l1_LR.fit(X, y)\n",
    "    clf_l2_LR.fit(X, y)\n",
    "    clf_en_LR.fit(X, y)\n",
    "\n",
    "    coef_l1_LR = clf_l1_LR.coef_.ravel()\n",
    "    coef_l2_LR = clf_l2_LR.coef_.ravel()\n",
    "    coef_en_LR = clf_en_LR.coef_.ravel()\n",
    "\n",
    "    # coef_l1_LR contains zeros due to the\n",
    "    # L1 sparsity inducing norm\n",
    "\n",
    "    sparsity_l1_LR = np.mean(coef_l1_LR == 0) * 100\n",
    "    sparsity_l2_LR = np.mean(coef_l2_LR == 0) * 100\n",
    "    sparsity_en_LR = np.mean(coef_en_LR == 0) * 100\n",
    "\n",
    "    print(\"C=%.2f\" % C)\n",
    "    print(\"{:<40} {:.2f}%\".format(\"Sparsity with L1 penalty:\", sparsity_l1_LR))\n",
    "    print(\"{:<40} {:.2f}%\".format(\"Sparsity with Elastic-Net penalty:\",\n",
    "                                  sparsity_en_LR))\n",
    "    print(\"{:<40} {:.2f}%\".format(\"Sparsity with L2 penalty:\", sparsity_l2_LR))\n",
    "    print(\"{:<40} {:.2f}\".format(\"Score with L1 penalty:\",\n",
    "                                 clf_l1_LR.score(X, y)))\n",
    "    print(\"{:<40} {:.2f}\".format(\"Score with Elastic-Net penalty:\",\n",
    "                                 clf_en_LR.score(X, y)))\n",
    "    print(\"{:<40} {:.2f}\".format(\"Score with L2 penalty:\",\n",
    "                                 clf_l2_LR.score(X, y)))\n",
    "\n",
    "    if i == 0:\n",
    "        axes_row[0].set_title(\"L1 penalty\")\n",
    "        axes_row[1].set_title(\"Elastic-Net\\nl1_ratio = %s\" % l1_ratio)\n",
    "        axes_row[2].set_title(\"L2 penalty\")\n",
    "\n",
    "    for ax, coefs in zip(axes_row, [coef_l1_LR, coef_en_LR, coef_l2_LR]):\n",
    "        ax.imshow(np.abs(coefs.reshape(8, 8)), interpolation='nearest',\n",
    "                  cmap='binary', vmax=1, vmin=0)\n",
    "        ax.set_xticks(())\n",
    "        ax.set_yticks(())\n",
    "\n",
    "    axes_row[0].set_ylabel('C = %s' % C)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
