{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site</th>\n",
       "      <th>Code</th>\n",
       "      <th>SAincl</th>\n",
       "      <th>SA2</th>\n",
       "      <th>SA4</th>\n",
       "      <th>SA6</th>\n",
       "      <th>SA8</th>\n",
       "      <th>SA10</th>\n",
       "      <th>SA12</th>\n",
       "      <th>SA1416</th>\n",
       "      <th>...</th>\n",
       "      <th>TempPara5</th>\n",
       "      <th>VitD</th>\n",
       "      <th>VitD3Groups</th>\n",
       "      <th>ThreeUTR</th>\n",
       "      <th>ThreeUTRvar</th>\n",
       "      <th>INT4</th>\n",
       "      <th>INT4var</th>\n",
       "      <th>D543</th>\n",
       "      <th>Callele</th>\n",
       "      <th>Callelevar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>401</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>402</td>\n",
       "      <td>11.3</td>\n",
       "      <td>13.3</td>\n",
       "      <td>18.9</td>\n",
       "      <td>20.1</td>\n",
       "      <td>26.2</td>\n",
       "      <td>34.7</td>\n",
       "      <td>29.9</td>\n",
       "      <td>33.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>403</td>\n",
       "      <td>15.4</td>\n",
       "      <td>9.9</td>\n",
       "      <td>9.5</td>\n",
       "      <td>9.5</td>\n",
       "      <td>8.3</td>\n",
       "      <td>8.7</td>\n",
       "      <td>6.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>404</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>405</td>\n",
       "      <td>33.0</td>\n",
       "      <td>24.1</td>\n",
       "      <td>12.3</td>\n",
       "      <td>11.8</td>\n",
       "      <td>8.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Site  Code  SAincl   SA2   SA4   SA6   SA8  SA10  SA12  SA1416  ...  \\\n",
       "0   1.0   401     8.3   1.0   2.8   3.3   1.2   1.1   1.1     1.1  ...   \n",
       "1   1.0   402    11.3  13.3  18.9  20.1  26.2  34.7  29.9    33.0  ...   \n",
       "2   1.0   403    15.4   9.9   9.5   9.5   8.3   8.7   6.4     3.9  ...   \n",
       "3   1.0   404     0.5   0.2   0.0   0.0   0.0   0.0   0.0     0.0  ...   \n",
       "4   1.0   405    33.0  24.1  12.3  11.8   8.7   3.3   3.1     3.1  ...   \n",
       "\n",
       "   TempPara5  VitD  VitD3Groups  ThreeUTR  ThreeUTRvar  INT4  INT4var  D543  \\\n",
       "0        NaN   NaN          NaN       NaN          NaN   NaN      NaN   NaN   \n",
       "1        NaN   NaN          NaN       NaN          NaN   NaN      NaN   NaN   \n",
       "2        NaN   NaN          NaN       NaN          NaN   NaN      NaN   NaN   \n",
       "3        NaN   NaN          NaN       NaN          NaN   NaN      NaN   NaN   \n",
       "4        NaN   NaN          NaN       NaN          NaN   NaN      NaN   NaN   \n",
       "\n",
       "   Callele  Callelevar  \n",
       "0      NaN         NaN  \n",
       "1      NaN         NaN  \n",
       "2      NaN         NaN  \n",
       "3      NaN         NaN  \n",
       "4      NaN         NaN  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('paradox.csv',sep= ',')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 241 entries, 0 to 240\n",
      "Data columns (total 49 columns):\n",
      "Site                     241 non-null float64\n",
      "Code                     241 non-null int64\n",
      "SAincl                   241 non-null float64\n",
      "SA2                      233 non-null float64\n",
      "SA4                      227 non-null float64\n",
      "SA6                      223 non-null float64\n",
      "SA8                      232 non-null float64\n",
      "SA10                     215 non-null float64\n",
      "SA12                     225 non-null float64\n",
      "SA1416                   223 non-null float64\n",
      "SA2120                   221 non-null float64\n",
      "SA2728                   211 non-null float64\n",
      "studyarm                 241 non-null float64\n",
      "sexe                     241 non-null float64\n",
      "age                      241 non-null int64\n",
      "lesionsince              240 non-null float64\n",
      "BPSYST                   216 non-null float64\n",
      "BPDIAST                  216 non-null float64\n",
      "pulserateinclbeatsmin    232 non-null float64\n",
      "tempinclCelsius          237 non-null float64\n",
      "bodyweightinclkg         241 non-null int64\n",
      "bodyheightinclcm         237 non-null float64\n",
      "WHOCat                   241 non-null float64\n",
      "stageincllesion          241 non-null int64\n",
      "oedemaincl               241 non-null int64\n",
      "lesnumbincl              91 non-null float64\n",
      "Sitelesion               239 non-null float64\n",
      "Hb                       237 non-null float64\n",
      "WBC                      237 non-null float64\n",
      "creatin                  240 non-null float64\n",
      "HIV                      241 non-null float64\n",
      "Drug                     241 non-null float64\n",
      "Paradox1                 241 non-null float64\n",
      "WeekParadox3             76 non-null float64\n",
      "Paradox2                 241 non-null float64\n",
      "WeekParadox5             241 non-null float64\n",
      "PulsePara3               33 non-null float64\n",
      "TempPara3                33 non-null float64\n",
      "PulsePara5               0 non-null float64\n",
      "TempPara5                0 non-null float64\n",
      "VitD                     144 non-null float64\n",
      "VitD3Groups              144 non-null float64\n",
      "ThreeUTR                 150 non-null float64\n",
      "ThreeUTRvar              150 non-null float64\n",
      "INT4                     150 non-null float64\n",
      "INT4var                  150 non-null float64\n",
      "D543                     150 non-null float64\n",
      "Callele                  150 non-null float64\n",
      "Callelevar               150 non-null float64\n",
      "dtypes: float64(44), int64(5)\n",
      "memory usage: 92.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Paradox1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace empty or errors by np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace empty/erros by np.nan\n",
    "df = df.replace(r'^\\s+$', np.nan, regex=True)\n",
    "df = df.replace('\\t','',regex=True)\n",
    "df = df.replace(' ','',regex=True)\n",
    "df = df.replace('\\?',np.nan,regex=True)\n",
    "df = df.replace('\\<',np.nan,regex=True)\n",
    "#df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site</th>\n",
       "      <th>SAincl</th>\n",
       "      <th>SA2</th>\n",
       "      <th>SA4</th>\n",
       "      <th>SA6</th>\n",
       "      <th>SA8</th>\n",
       "      <th>SA10</th>\n",
       "      <th>SA12</th>\n",
       "      <th>SA1416</th>\n",
       "      <th>SA2120</th>\n",
       "      <th>...</th>\n",
       "      <th>TempPara5</th>\n",
       "      <th>VitD</th>\n",
       "      <th>VitD3Groups</th>\n",
       "      <th>ThreeUTR</th>\n",
       "      <th>ThreeUTRvar</th>\n",
       "      <th>INT4</th>\n",
       "      <th>INT4var</th>\n",
       "      <th>D543</th>\n",
       "      <th>Callele</th>\n",
       "      <th>Callelevar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>13.3</td>\n",
       "      <td>18.9</td>\n",
       "      <td>20.1</td>\n",
       "      <td>26.2</td>\n",
       "      <td>34.7</td>\n",
       "      <td>29.9</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>15.4</td>\n",
       "      <td>9.9</td>\n",
       "      <td>9.5</td>\n",
       "      <td>9.5</td>\n",
       "      <td>8.3</td>\n",
       "      <td>8.7</td>\n",
       "      <td>6.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.7</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>24.1</td>\n",
       "      <td>12.3</td>\n",
       "      <td>11.8</td>\n",
       "      <td>8.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>7.1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Site  SAincl   SA2   SA4   SA6   SA8  SA10  SA12  SA1416  SA2120  ...  \\\n",
       "0   1.0     8.3   1.0   2.8   3.3   1.2   1.1   1.1     1.1     0.0  ...   \n",
       "1   1.0    11.3  13.3  18.9  20.1  26.2  34.7  29.9    33.0    33.0  ...   \n",
       "2   1.0    15.4   9.9   9.5   9.5   8.3   8.7   6.4     3.9     3.7  ...   \n",
       "3   1.0     0.5   0.2   0.0   0.0   0.0   0.0   0.0     0.0     0.0  ...   \n",
       "4   1.0    33.0  24.1  12.3  11.8   8.7   3.3   3.1     3.1     7.1  ...   \n",
       "\n",
       "   TempPara5  VitD  VitD3Groups  ThreeUTR  ThreeUTRvar  INT4  INT4var  D543  \\\n",
       "0        NaN   NaN          NaN       NaN          NaN   NaN      NaN   NaN   \n",
       "1        NaN   NaN          NaN       NaN          NaN   NaN      NaN   NaN   \n",
       "2        NaN   NaN          NaN       NaN          NaN   NaN      NaN   NaN   \n",
       "3        NaN   NaN          NaN       NaN          NaN   NaN      NaN   NaN   \n",
       "4        NaN   NaN          NaN       NaN          NaN   NaN      NaN   NaN   \n",
       "\n",
       "   Callele  Callelevar  \n",
       "0      NaN         NaN  \n",
       "1      NaN         NaN  \n",
       "2      NaN         NaN  \n",
       "3      NaN         NaN  \n",
       "4      NaN         NaN  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the column `Code` as it is unrelated to the dependent variable\n",
    "df = df.drop(['Code'],axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove bad columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_bad_columns(df,bad_column_threshold):\n",
    "    # find bad columns having too many missing values\n",
    "    n_null = np.array(df.isnull().sum(axis=0))\n",
    "    bad_col = np.array([]).astype(int)\n",
    "    for i in range(len(n_null)):\n",
    "        if n_null[i] >= bad_column_threshold:\n",
    "            bad_col = np.append(bad_col,i)\n",
    "\n",
    "    #print(bad_col)\n",
    "    print('number of bad columns:',len(bad_col))\n",
    "\n",
    "    # delete bad columns\n",
    "    df = df.drop(df.columns[bad_col],axis=1)\n",
    "    #df.info()\n",
    "    return df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of bad columns: 15\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 241 entries, 0 to 240\n",
      "Data columns (total 33 columns):\n",
      "Site                     241 non-null float64\n",
      "SAincl                   241 non-null float64\n",
      "SA2                      233 non-null float64\n",
      "SA4                      227 non-null float64\n",
      "SA6                      223 non-null float64\n",
      "SA8                      232 non-null float64\n",
      "SA10                     215 non-null float64\n",
      "SA12                     225 non-null float64\n",
      "SA1416                   223 non-null float64\n",
      "SA2120                   221 non-null float64\n",
      "SA2728                   211 non-null float64\n",
      "studyarm                 241 non-null float64\n",
      "sexe                     241 non-null float64\n",
      "age                      241 non-null int64\n",
      "lesionsince              240 non-null float64\n",
      "BPSYST                   216 non-null float64\n",
      "BPDIAST                  216 non-null float64\n",
      "pulserateinclbeatsmin    232 non-null float64\n",
      "tempinclCelsius          237 non-null float64\n",
      "bodyweightinclkg         241 non-null int64\n",
      "bodyheightinclcm         237 non-null float64\n",
      "WHOCat                   241 non-null float64\n",
      "stageincllesion          241 non-null int64\n",
      "oedemaincl               241 non-null int64\n",
      "Sitelesion               239 non-null float64\n",
      "Hb                       237 non-null float64\n",
      "WBC                      237 non-null float64\n",
      "creatin                  240 non-null float64\n",
      "HIV                      241 non-null float64\n",
      "Drug                     241 non-null float64\n",
      "Paradox1                 241 non-null float64\n",
      "Paradox2                 241 non-null float64\n",
      "WeekParadox5             241 non-null float64\n",
      "dtypes: float64(29), int64(4)\n",
      "memory usage: 62.2 KB\n"
     ]
    }
   ],
   "source": [
    "df = remove_bad_columns(df,40)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove bad rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Find rows where target is missing\n",
    "def find_missing_target_rows(df,target):\n",
    "    # find rows where target is missing\n",
    "    missing_row = df[target].isnull()\n",
    "    print('Number of rows where target are missing:')\n",
    "    print(sum(missing_row))\n",
    "\n",
    "    #df = df[~missing_row]\n",
    "    missing_row_indices = np.array([t for t in range(df.shape[0]) if missing_row[t]])\n",
    "    \n",
    "    return missing_row_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows where target are missing:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "missing_target_rows = find_missing_target_rows(df,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find bad rows which contain too many missing values, then remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_bad_rows(df,bad_row_threshold):   \n",
    "    # find bad rows having too many missing values\n",
    "    n_null = np.array(df.isnull().sum(axis=1))\n",
    "    bad_row = np.array([]).astype(int)\n",
    "    for t in range(len(n_null)):\n",
    "        if n_null[t] >= bad_row_threshold:\n",
    "            bad_row = np.append(bad_row,t)\n",
    "\n",
    "    #print(bad_row)\n",
    "    print('number of bad rows:',len(bad_row))\n",
    "\n",
    "    # delete bad rows\n",
    "    #df = df.drop(bad_row)\n",
    "    #df.info()\n",
    "    return bad_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of bad rows: 12\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 241 entries, 0 to 240\n",
      "Data columns (total 33 columns):\n",
      "Site                     241 non-null float64\n",
      "SAincl                   241 non-null float64\n",
      "SA2                      233 non-null float64\n",
      "SA4                      227 non-null float64\n",
      "SA6                      223 non-null float64\n",
      "SA8                      232 non-null float64\n",
      "SA10                     215 non-null float64\n",
      "SA12                     225 non-null float64\n",
      "SA1416                   223 non-null float64\n",
      "SA2120                   221 non-null float64\n",
      "SA2728                   211 non-null float64\n",
      "studyarm                 241 non-null float64\n",
      "sexe                     241 non-null float64\n",
      "age                      241 non-null int64\n",
      "lesionsince              240 non-null float64\n",
      "BPSYST                   216 non-null float64\n",
      "BPDIAST                  216 non-null float64\n",
      "pulserateinclbeatsmin    232 non-null float64\n",
      "tempinclCelsius          237 non-null float64\n",
      "bodyweightinclkg         241 non-null int64\n",
      "bodyheightinclcm         237 non-null float64\n",
      "WHOCat                   241 non-null float64\n",
      "stageincllesion          241 non-null int64\n",
      "oedemaincl               241 non-null int64\n",
      "Sitelesion               239 non-null float64\n",
      "Hb                       237 non-null float64\n",
      "WBC                      237 non-null float64\n",
      "creatin                  240 non-null float64\n",
      "HIV                      241 non-null float64\n",
      "Drug                     241 non-null float64\n",
      "Paradox1                 241 non-null float64\n",
      "Paradox2                 241 non-null float64\n",
      "WeekParadox5             241 non-null float64\n",
      "dtypes: float64(29), int64(4)\n",
      "memory usage: 62.2 KB\n"
     ]
    }
   ],
   "source": [
    "bad_rows = find_bad_rows(df,5)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows need to delete: 12\n"
     ]
    }
   ],
   "source": [
    "del_rows = np.union1d(missing_target_rows,bad_rows)\n",
    "print('number of rows need to delete:',len(del_rows))\n",
    "\n",
    "df = df.drop(del_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate target and attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx = df.drop(target,axis=1)\n",
    "dfy = df[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find variable type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of uniques of each variable:\n",
      "[  2 177 155 151 121 129 117 121 112  74  46   4   2  41  21  13  12  75\n",
      "  33  59  78   3   5   3   4 119 106  81   2   2   2   8]\n"
     ]
    }
   ],
   "source": [
    "# number of uniques of each column (excluding NaN)\n",
    "nu = np.array([len(pd.unique(dfx[col].dropna())) for col in dfx.columns])\n",
    "print('number of uniques of each variable:')\n",
    "print(nu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def define_variable_type(df,nu):\n",
    "    i_binary = [] ; i_category = [] ; i_continuous = []\n",
    "    for i in range(len(nu)):\n",
    "        if nu[i] == 2: # binary \n",
    "            i_binary.append(i)\n",
    "        elif nu[i] < 5: # !!!! NOTE: this is not always correct, depending on data\n",
    "            i_category.append(i)\n",
    "        else:\n",
    "            i_continuous.append(i)\n",
    "\n",
    "    print('i_binary:',i_binary)\n",
    "    print('i_category:',i_category)   \n",
    "    #i_binary, i_category, i_continuous\n",
    "    \n",
    "    variable_type  = np.ones(len(nu))  # binary\n",
    "    variable_type[i_category] = 2   # categorical\n",
    "    variable_type[i_continuous] = 3 # continuous\n",
    "\n",
    "    return variable_type #,i_binary,i_category,i_continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i_binary: [0, 12, 28, 29, 30]\n",
      "i_category: [11, 21, 23, 24]\n",
      "variable type: [1. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 2. 1. 3. 3. 3. 3. 3. 3. 3. 3. 2. 3. 2.\n",
      " 2. 3. 3. 3. 1. 1. 1. 3.]\n"
     ]
    }
   ],
   "source": [
    "variable_type = define_variable_type(dfx,nu)\n",
    "print('variable type:',variable_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute missing values of attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing(df,variable_type):\n",
    "    # impute binary and categorical variables by the most frequency (in each column)\n",
    "    # continuous variable by median\n",
    "    # input: df: pandas data frame, variable_type: list\n",
    "    # output: df2: pandas data frame\n",
    "    df2 = df.copy()\n",
    "    for i,col in enumerate(df.columns):\n",
    "        if variable_type[i] < 3: # binary or caterogy\n",
    "            df2[col] = df[col].fillna(df[col].mode().iloc[0])\n",
    "        else: # continuous\n",
    "            df2[col] = df[col].fillna(df[col].median())    \n",
    "    return df2       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 229 entries, 0 to 240\n",
      "Data columns (total 32 columns):\n",
      "Site                     229 non-null float64\n",
      "SAincl                   229 non-null float64\n",
      "SA2                      229 non-null float64\n",
      "SA4                      229 non-null float64\n",
      "SA6                      229 non-null float64\n",
      "SA8                      229 non-null float64\n",
      "SA10                     229 non-null float64\n",
      "SA12                     229 non-null float64\n",
      "SA1416                   229 non-null float64\n",
      "SA2120                   229 non-null float64\n",
      "SA2728                   229 non-null float64\n",
      "studyarm                 229 non-null float64\n",
      "sexe                     229 non-null float64\n",
      "age                      229 non-null int64\n",
      "lesionsince              229 non-null float64\n",
      "BPSYST                   229 non-null float64\n",
      "BPDIAST                  229 non-null float64\n",
      "pulserateinclbeatsmin    229 non-null float64\n",
      "tempinclCelsius          229 non-null float64\n",
      "bodyweightinclkg         229 non-null int64\n",
      "bodyheightinclcm         229 non-null float64\n",
      "WHOCat                   229 non-null float64\n",
      "stageincllesion          229 non-null int64\n",
      "oedemaincl               229 non-null int64\n",
      "Sitelesion               229 non-null float64\n",
      "Hb                       229 non-null float64\n",
      "WBC                      229 non-null float64\n",
      "creatin                  229 non-null float64\n",
      "HIV                      229 non-null float64\n",
      "Drug                     229 non-null float64\n",
      "Paradox2                 229 non-null float64\n",
      "WeekParadox5             229 non-null float64\n",
      "dtypes: float64(28), int64(4)\n",
      "memory usage: 59.0 KB\n"
     ]
    }
   ],
   "source": [
    "dfx_imputed = impute_missing(dfx,variable_type)\n",
    "dfx_imputed.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_binary_and_category(x,variable_type):\n",
    "    \"\"\"\n",
    "    convert binary to +-1, category to one hot; remain continuous.\n",
    "    \"\"\"    \n",
    "    onehot_encoder = OneHotEncoder(sparse=False,categories='auto')\n",
    "\n",
    "    # create 2 initial columns\n",
    "    x_new = np.zeros((x.shape[0],2))\n",
    "\n",
    "    for i,i_type in enumerate(variable_type):\n",
    "        if i_type == 1: # binary\n",
    "            unique_value = np.unique(x[:,i])\n",
    "            x1 = np.array([-1. if value == unique_value[0] else 1. for value in x[:,i]])        \n",
    "            x_new = np.hstack((x_new,x1[:,np.newaxis]))\n",
    "\n",
    "        elif i_type == 2: # category\n",
    "            x1 = onehot_encoder.fit_transform(x[:,i].reshape(-1,1))\n",
    "            x_new = np.hstack((x_new,x1))\n",
    "            \n",
    "        else: # continuous      \n",
    "            x_new = np.hstack((x_new,x[:,i][:,np.newaxis]))      \n",
    "\n",
    "    # drop the 2 initial column\n",
    "    x_new = x_new[:,2:]\n",
    "    \n",
    "    return x_new.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(229, 42)\n",
      "[[-1.   8.3  1.  ... -1.   1.   6. ]\n",
      " [-1.  11.3 13.3 ... -1.  -1.   0. ]\n",
      " [-1.  15.4  9.9 ... -1.  -1.   0. ]\n",
      " ...\n",
      " [ 1.  38.4 10.6 ... -1.  -1.   0. ]\n",
      " [ 1.  68.1 79.2 ... -1.   1.  10. ]\n",
      " [ 1.   4.   1.5 ...  1.  -1.   0. ]]\n"
     ]
    }
   ],
   "source": [
    "# convert x\n",
    "x = np.array(dfx_imputed)\n",
    "x_new = convert_binary_and_category(x,variable_type)\n",
    "\n",
    "print(x_new.shape)\n",
    "print(x_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0., 1.]), array([169,  60]))\n"
     ]
    }
   ],
   "source": [
    "y = np.array(dfy)\n",
    "#print(np.unique(y,return_counts=True))\n",
    "\n",
    "# convert taget to 0 and 1\n",
    "y_new = y\n",
    "#y_new = np.ones(y.shape[0])\n",
    "#y_new[y =='No'] = 0\n",
    "\n",
    "print(np.unique(y_new,return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine X and y and save to a file\n",
    "xy_new = np.hstack((x_new,y_new[:,np.newaxis]))\n",
    "np.savetxt('data_processed.dat',xy_new,fmt='%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
