{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2_completed_education</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>...</th>\n",
       "      <th>Low</th>\n",
       "      <th>Middle</th>\n",
       "      <th>High</th>\n",
       "      <th>Not_applicable</th>\n",
       "      <th>Smoke_daily</th>\n",
       "      <th>Smoke_less_then_daily</th>\n",
       "      <th>Smoked_in_the_past</th>\n",
       "      <th>Never_smoker</th>\n",
       "      <th>a62_income</th>\n",
       "      <th>a4_smoking_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 119 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  gender  A1  A2_completed_education  A3  A4  A5   A6   A7   A8  ...  \\\n",
       "0   35       2   1                       2   2   1 NaN  2.0  3.0  1.0  ...   \n",
       "1   34       1   4                       3   3   1 NaN  2.0  3.0  1.0  ...   \n",
       "2   37       2   3                       3   3   1 NaN  4.0  2.0  1.0  ...   \n",
       "3   37       2   3                       3   3   1 NaN  4.0  2.0  1.0  ...   \n",
       "4   35       2   2                       3   3   3 NaN  NaN  NaN  NaN  ...   \n",
       "\n",
       "   Low  Middle  High  Not_applicable  Smoke_daily  Smoke_less_then_daily  \\\n",
       "0  1.0     0.0   0.0             0.0          1.0                    0.0   \n",
       "1  1.0     0.0   0.0             0.0          1.0                    0.0   \n",
       "2  0.0     0.0   1.0             0.0          1.0                    0.0   \n",
       "3  0.0     0.0   1.0             0.0          1.0                    0.0   \n",
       "4  0.0     0.0   1.0             0.0          0.0                    0.0   \n",
       "\n",
       "   Smoked_in_the_past  Never_smoker  a62_income  a4_smoking_status  \n",
       "0                 0.0           0.0         1.0                1.0  \n",
       "1                 0.0           0.0         1.0                1.0  \n",
       "2                 0.0           0.0         3.0                1.0  \n",
       "3                 0.0           0.0         3.0                1.0  \n",
       "4                 1.0           0.0         3.0                3.0  \n",
       "\n",
       "[5 rows x 119 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"smoking.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1588 entries, 0 to 1587\n",
      "Columns: 119 entries, age to a4_smoking_status\n",
      "dtypes: float64(49), int64(70)\n",
      "memory usage: 1.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'healthstatus3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace empty or errors by np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace empty/erros by np.nan\n",
    "df = df.replace(r'^\\s+$', np.nan, regex=True)\n",
    "df = df.replace('\\t','',regex=True)\n",
    "df = df.replace(' ','',regex=True)\n",
    "df = df.replace('\\?',np.nan,regex=True)\n",
    "df = df.replace('\\<',np.nan,regex=True)\n",
    "df = df.replace('#NULL!',np.nan,regex=True)\n",
    "df = df.replace('99',np.nan,regex=True)\n",
    "df = df.replace(99,np.nan,regex=True)\n",
    "#df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2_completed_education</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>...</th>\n",
       "      <th>Low</th>\n",
       "      <th>Middle</th>\n",
       "      <th>High</th>\n",
       "      <th>Not_applicable</th>\n",
       "      <th>Smoke_daily</th>\n",
       "      <th>Smoke_less_then_daily</th>\n",
       "      <th>Smoked_in_the_past</th>\n",
       "      <th>Never_smoker</th>\n",
       "      <th>a62_income</th>\n",
       "      <th>a4_smoking_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 119 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  gender  A1  A2_completed_education  A3  A4  A5   A6   A7   A8  ...  \\\n",
       "0   35       2   1                       2   2   1 NaN  2.0  3.0  1.0  ...   \n",
       "1   34       1   4                       3   3   1 NaN  2.0  3.0  1.0  ...   \n",
       "2   37       2   3                       3   3   1 NaN  4.0  2.0  1.0  ...   \n",
       "3   37       2   3                       3   3   1 NaN  4.0  2.0  1.0  ...   \n",
       "4   35       2   2                       3   3   3 NaN  NaN  NaN  NaN  ...   \n",
       "\n",
       "   Low  Middle  High  Not_applicable  Smoke_daily  Smoke_less_then_daily  \\\n",
       "0  1.0     0.0   0.0             0.0          1.0                    0.0   \n",
       "1  1.0     0.0   0.0             0.0          1.0                    0.0   \n",
       "2  0.0     0.0   1.0             0.0          1.0                    0.0   \n",
       "3  0.0     0.0   1.0             0.0          1.0                    0.0   \n",
       "4  0.0     0.0   1.0             0.0          0.0                    0.0   \n",
       "\n",
       "   Smoked_in_the_past  Never_smoker  a62_income  a4_smoking_status  \n",
       "0                 0.0           0.0         1.0                1.0  \n",
       "1                 0.0           0.0         1.0                1.0  \n",
       "2                 0.0           0.0         3.0                1.0  \n",
       "3                 0.0           0.0         3.0                1.0  \n",
       "4                 1.0           0.0         3.0                3.0  \n",
       "\n",
       "[5 rows x 119 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the column outliers as it is unrelated to the dependent variable\n",
    "outliers = []\n",
    "df = df.drop(outliers,axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove bad columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_bad_columns(df,bad_column_threshold):\n",
    "    # find bad columns having too many missing values\n",
    "    n_null = np.array(df.isnull().sum(axis=0))\n",
    "    bad_col = np.array([]).astype(int)\n",
    "    for i in range(len(n_null)):\n",
    "        if n_null[i] >= bad_column_threshold:\n",
    "            bad_col = np.append(bad_col,i)\n",
    "\n",
    "    #print(bad_col)\n",
    "    print('number of bad columns:',len(bad_col))\n",
    "\n",
    "    # delete bad columns\n",
    "    df = df.drop(df.columns[bad_col],axis=1)\n",
    "    #df.info()\n",
    "    return df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of bad columns: 23\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1588 entries, 0 to 1587\n",
      "Data columns (total 96 columns):\n",
      "age                             1588 non-null int64\n",
      "gender                          1588 non-null int64\n",
      "A1                              1588 non-null int64\n",
      "A2_completed_education          1588 non-null int64\n",
      "A3                              1588 non-null int64\n",
      "A4                              1588 non-null int64\n",
      "A9                              1571 non-null float64\n",
      "A16                             1587 non-null float64\n",
      "A17                             1587 non-null float64\n",
      "A18                             1588 non-null int64\n",
      "A19                             1588 non-null int64\n",
      "A20                             1588 non-null int64\n",
      "A21                             1556 non-null float64\n",
      "A22                             1585 non-null float64\n",
      "A23                             1588 non-null int64\n",
      "A24                             1588 non-null int64\n",
      "A25                             1588 non-null int64\n",
      "A26                             1497 non-null float64\n",
      "A30                             1536 non-null float64\n",
      "A31                             1548 non-null float64\n",
      "A32                             1552 non-null float64\n",
      "A33                             1524 non-null float64\n",
      "A34                             1554 non-null float64\n",
      "A35                             1547 non-null float64\n",
      "A37                             1528 non-null float64\n",
      "A38                             1521 non-null float64\n",
      "A39                             1535 non-null float64\n",
      "A40                             1540 non-null float64\n",
      "A46                             1567 non-null float64\n",
      "A47                             1567 non-null float64\n",
      "A48                             1546 non-null float64\n",
      "A49                             1570 non-null float64\n",
      "A50                             1571 non-null float64\n",
      "A51                             1567 non-null float64\n",
      "A52                             1558 non-null float64\n",
      "A53                             1559 non-null float64\n",
      "A54                             1570 non-null float64\n",
      "A55                             1572 non-null float64\n",
      "A56                             1563 non-null float64\n",
      "A57                             1565 non-null float64\n",
      "A58                             1512 non-null float64\n",
      "A59                             1553 non-null float64\n",
      "A60                             1588 non-null int64\n",
      "A61                             1588 non-null int64\n",
      "A62                             1569 non-null float64\n",
      "A67                             1557 non-null float64\n",
      "A68                             1558 non-null float64\n",
      "A69                             1488 non-null float64\n",
      "agecatage                       1588 non-null int64\n",
      "maritalstatusa1                 1588 non-null int64\n",
      "Regiona61                       1588 non-null int64\n",
      "healthstatus3                   1588 non-null int64\n",
      "Sales_rest                      1588 non-null int64\n",
      "Sales_rest_category             1588 non-null int64\n",
      "Sales_rest_category_Negative    1588 non-null int64\n",
      "Sales_rest_category_low         1588 non-null int64\n",
      "Sales_rest_category_high        1588 non-null int64\n",
      "SalesHighSupport                1588 non-null int64\n",
      "A55_a                           1571 non-null float64\n",
      "A56_a                           1563 non-null float64\n",
      "A57_a                           1565 non-null float64\n",
      "A58_a                           1512 non-null float64\n",
      "A38_valid                       1521 non-null float64\n",
      "bb                              1588 non-null int64\n",
      "A38_rec                         1588 non-null int64\n",
      "A39_rec                         1588 non-null int64\n",
      "A40_rec                         1588 non-null int64\n",
      "A55_rec                         1588 non-null int64\n",
      "A56_rec                         1588 non-null int64\n",
      "A57_rec                         1588 non-null int64\n",
      "A58_rec                         1588 non-null int64\n",
      "A59_rec                         1588 non-null int64\n",
      "II_STATIA                       1574 non-null float64\n",
      "filter_$                        1588 non-null int64\n",
      "attit2                          1588 non-null int64\n",
      "support0_8                      1574 non-null float64\n",
      "age_13_25                       1574 non-null float64\n",
      "age_26_35                       1574 non-null float64\n",
      "age_36_45                       1574 non-null float64\n",
      "age_46_55                       1574 non-null float64\n",
      "age_56_70                       1574 non-null float64\n",
      "female                          1574 non-null float64\n",
      "male                            1574 non-null float64\n",
      "Primary_or_Secondary            1574 non-null float64\n",
      "Middle_college                  1574 non-null float64\n",
      "University                      1574 non-null float64\n",
      "Low                             1574 non-null float64\n",
      "Middle                          1574 non-null float64\n",
      "High                            1574 non-null float64\n",
      "Not_applicable                  1574 non-null float64\n",
      "Smoke_daily                     1574 non-null float64\n",
      "Smoke_less_then_daily           1574 non-null float64\n",
      "Smoked_in_the_past              1574 non-null float64\n",
      "Never_smoker                    1574 non-null float64\n",
      "a62_income                      1569 non-null float64\n",
      "a4_smoking_status               1588 non-null float64\n",
      "dtypes: float64(61), int64(35)\n",
      "memory usage: 1.2 MB\n"
     ]
    }
   ],
   "source": [
    "df = remove_bad_columns(df,200)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove bad rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Find rows where target is missing\n",
    "def find_missing_target_rows(df,target):\n",
    "    # find rows where target is missing\n",
    "    missing_row = df[target].isnull()\n",
    "    print('Number of rows where target are missing:')\n",
    "    print(sum(missing_row))\n",
    "\n",
    "    #df = df[~missing_row]\n",
    "    missing_row_indices = np.array([t for t in range(df.shape[0]) if missing_row[t]])\n",
    "    \n",
    "    return missing_row_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows where target are missing:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "missing_target_rows = find_missing_target_rows(df,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find bad rows which contain too many missing values, then remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_bad_rows(df,bad_row_threshold):   \n",
    "    # find bad rows having too many missing values\n",
    "    n_null = np.array(df.isnull().sum(axis=1))\n",
    "    bad_row = np.array([]).astype(int)\n",
    "    for t in range(len(n_null)):\n",
    "        if n_null[t] >= bad_row_threshold:\n",
    "            bad_row = np.append(bad_row,t)\n",
    "\n",
    "    #print(bad_row)\n",
    "    print('number of bad rows:',len(bad_row))\n",
    "\n",
    "    # delete bad rows\n",
    "    #df = df.drop(bad_row)\n",
    "    #df.info()\n",
    "    return bad_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of bad rows: 14\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1588 entries, 0 to 1587\n",
      "Data columns (total 96 columns):\n",
      "age                             1588 non-null int64\n",
      "gender                          1588 non-null int64\n",
      "A1                              1588 non-null int64\n",
      "A2_completed_education          1588 non-null int64\n",
      "A3                              1588 non-null int64\n",
      "A4                              1588 non-null int64\n",
      "A9                              1571 non-null float64\n",
      "A16                             1587 non-null float64\n",
      "A17                             1587 non-null float64\n",
      "A18                             1588 non-null int64\n",
      "A19                             1588 non-null int64\n",
      "A20                             1588 non-null int64\n",
      "A21                             1556 non-null float64\n",
      "A22                             1585 non-null float64\n",
      "A23                             1588 non-null int64\n",
      "A24                             1588 non-null int64\n",
      "A25                             1588 non-null int64\n",
      "A26                             1497 non-null float64\n",
      "A30                             1536 non-null float64\n",
      "A31                             1548 non-null float64\n",
      "A32                             1552 non-null float64\n",
      "A33                             1524 non-null float64\n",
      "A34                             1554 non-null float64\n",
      "A35                             1547 non-null float64\n",
      "A37                             1528 non-null float64\n",
      "A38                             1521 non-null float64\n",
      "A39                             1535 non-null float64\n",
      "A40                             1540 non-null float64\n",
      "A46                             1567 non-null float64\n",
      "A47                             1567 non-null float64\n",
      "A48                             1546 non-null float64\n",
      "A49                             1570 non-null float64\n",
      "A50                             1571 non-null float64\n",
      "A51                             1567 non-null float64\n",
      "A52                             1558 non-null float64\n",
      "A53                             1559 non-null float64\n",
      "A54                             1570 non-null float64\n",
      "A55                             1572 non-null float64\n",
      "A56                             1563 non-null float64\n",
      "A57                             1565 non-null float64\n",
      "A58                             1512 non-null float64\n",
      "A59                             1553 non-null float64\n",
      "A60                             1588 non-null int64\n",
      "A61                             1588 non-null int64\n",
      "A62                             1569 non-null float64\n",
      "A67                             1557 non-null float64\n",
      "A68                             1558 non-null float64\n",
      "A69                             1488 non-null float64\n",
      "agecatage                       1588 non-null int64\n",
      "maritalstatusa1                 1588 non-null int64\n",
      "Regiona61                       1588 non-null int64\n",
      "healthstatus3                   1588 non-null int64\n",
      "Sales_rest                      1588 non-null int64\n",
      "Sales_rest_category             1588 non-null int64\n",
      "Sales_rest_category_Negative    1588 non-null int64\n",
      "Sales_rest_category_low         1588 non-null int64\n",
      "Sales_rest_category_high        1588 non-null int64\n",
      "SalesHighSupport                1588 non-null int64\n",
      "A55_a                           1571 non-null float64\n",
      "A56_a                           1563 non-null float64\n",
      "A57_a                           1565 non-null float64\n",
      "A58_a                           1512 non-null float64\n",
      "A38_valid                       1521 non-null float64\n",
      "bb                              1588 non-null int64\n",
      "A38_rec                         1588 non-null int64\n",
      "A39_rec                         1588 non-null int64\n",
      "A40_rec                         1588 non-null int64\n",
      "A55_rec                         1588 non-null int64\n",
      "A56_rec                         1588 non-null int64\n",
      "A57_rec                         1588 non-null int64\n",
      "A58_rec                         1588 non-null int64\n",
      "A59_rec                         1588 non-null int64\n",
      "II_STATIA                       1574 non-null float64\n",
      "filter_$                        1588 non-null int64\n",
      "attit2                          1588 non-null int64\n",
      "support0_8                      1574 non-null float64\n",
      "age_13_25                       1574 non-null float64\n",
      "age_26_35                       1574 non-null float64\n",
      "age_36_45                       1574 non-null float64\n",
      "age_46_55                       1574 non-null float64\n",
      "age_56_70                       1574 non-null float64\n",
      "female                          1574 non-null float64\n",
      "male                            1574 non-null float64\n",
      "Primary_or_Secondary            1574 non-null float64\n",
      "Middle_college                  1574 non-null float64\n",
      "University                      1574 non-null float64\n",
      "Low                             1574 non-null float64\n",
      "Middle                          1574 non-null float64\n",
      "High                            1574 non-null float64\n",
      "Not_applicable                  1574 non-null float64\n",
      "Smoke_daily                     1574 non-null float64\n",
      "Smoke_less_then_daily           1574 non-null float64\n",
      "Smoked_in_the_past              1574 non-null float64\n",
      "Never_smoker                    1574 non-null float64\n",
      "a62_income                      1569 non-null float64\n",
      "a4_smoking_status               1588 non-null float64\n",
      "dtypes: float64(61), int64(35)\n",
      "memory usage: 1.2 MB\n"
     ]
    }
   ],
   "source": [
    "bad_rows = find_bad_rows(df,10)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows need to delete: 14\n"
     ]
    }
   ],
   "source": [
    "del_rows = np.union1d(missing_target_rows,bad_rows)\n",
    "print('number of rows need to delete:',len(del_rows))\n",
    "\n",
    "df = df.drop(del_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate target and attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx = df.drop(target,axis=1)\n",
    "dfy = df[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find variable type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of uniques of each variable:\n",
      "[  58    2    5    3    5    4    5    2    2    2    2    2    2    3\n",
      "    3    3    3    5    2    2    2    3    2    2    2    2    2    2\n",
      "    7    8    2    2    2    2    2    2    2    3    3    3    3    2\n",
      " 1565   10    3    2    2    2    5    2    3    7    3    2    2    2\n",
      "    2    2    2    2    2    2    4    2    2    2    2    2    2    2\n",
      "    2    9    2    9    2    2    2    2    2    2    2    2    2    2\n",
      "    2    2    2    2    2    2    2    2    2    3    4]\n"
     ]
    }
   ],
   "source": [
    "# number of uniques of each column (excluding NaN)\n",
    "nu = np.array([len(pd.unique(dfx[col].dropna())) for col in dfx.columns])\n",
    "print('number of uniques of each variable:')\n",
    "print(nu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def define_variable_type(df,nu):\n",
    "    i_binary = [] ; i_category = [] ; i_continuous = []\n",
    "    for i in range(len(nu)):\n",
    "        if nu[i] == 2: # binary \n",
    "            i_binary.append(i)\n",
    "        elif nu[i] < 5: # !!!! NOTE: this is not always correct, depending on data\n",
    "            i_category.append(i)\n",
    "        else:\n",
    "            i_continuous.append(i)\n",
    "\n",
    "    print('i_binary:',i_binary)\n",
    "    print('i_category:',i_category)   \n",
    "    #i_binary, i_category, i_continuous\n",
    "    \n",
    "    variable_type  = np.ones(len(nu))  # binary\n",
    "    variable_type[i_category] = 2   # categorical\n",
    "    variable_type[i_continuous] = 3 # continuous\n",
    "\n",
    "    return variable_type #,i_binary,i_category,i_continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i_binary: [1, 7, 8, 9, 10, 11, 12, 18, 19, 20, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 41, 45, 46, 47, 49, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92]\n",
      "i_category: [3, 5, 13, 14, 15, 16, 21, 37, 38, 39, 40, 44, 50, 52, 62, 93, 94]\n",
      "variable type: [3. 1. 3. 2. 3. 2. 3. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 3. 1. 1. 1. 2. 1. 1.\n",
      " 1. 1. 1. 1. 3. 3. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 1. 3. 3. 2. 1. 1. 1.\n",
      " 3. 1. 2. 3. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 1. 1. 1. 1. 1. 1. 1. 1. 3.\n",
      " 1. 3. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "variable_type = define_variable_type(dfx,nu)\n",
    "print('variable type:',variable_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute missing values of attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing(df,variable_type):\n",
    "    # impute binary and categorical variables by the most frequency (in each column)\n",
    "    # continuous variable by median\n",
    "    # input: df: pandas data frame, variable_type: list\n",
    "    # output: df2: pandas data frame\n",
    "    df2 = df.copy()\n",
    "    for i,col in enumerate(df.columns):\n",
    "        if variable_type[i] < 3: # binary or caterogy\n",
    "            df2[col] = df[col].fillna(df[col].mode().iloc[0])\n",
    "        else: # continuous\n",
    "            df2[col] = df[col].fillna(df[col].median())    \n",
    "    return df2       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1574 entries, 0 to 1573\n",
      "Data columns (total 95 columns):\n",
      "age                             1574 non-null int64\n",
      "gender                          1574 non-null int64\n",
      "A1                              1574 non-null int64\n",
      "A2_completed_education          1574 non-null int64\n",
      "A3                              1574 non-null int64\n",
      "A4                              1574 non-null int64\n",
      "A9                              1574 non-null float64\n",
      "A16                             1574 non-null float64\n",
      "A17                             1574 non-null float64\n",
      "A18                             1574 non-null int64\n",
      "A19                             1574 non-null int64\n",
      "A20                             1574 non-null int64\n",
      "A21                             1574 non-null float64\n",
      "A22                             1574 non-null float64\n",
      "A23                             1574 non-null int64\n",
      "A24                             1574 non-null int64\n",
      "A25                             1574 non-null int64\n",
      "A26                             1574 non-null float64\n",
      "A30                             1574 non-null float64\n",
      "A31                             1574 non-null float64\n",
      "A32                             1574 non-null float64\n",
      "A33                             1574 non-null float64\n",
      "A34                             1574 non-null float64\n",
      "A35                             1574 non-null float64\n",
      "A37                             1574 non-null float64\n",
      "A38                             1574 non-null float64\n",
      "A39                             1574 non-null float64\n",
      "A40                             1574 non-null float64\n",
      "A46                             1574 non-null float64\n",
      "A47                             1574 non-null float64\n",
      "A48                             1574 non-null float64\n",
      "A49                             1574 non-null float64\n",
      "A50                             1574 non-null float64\n",
      "A51                             1574 non-null float64\n",
      "A52                             1574 non-null float64\n",
      "A53                             1574 non-null float64\n",
      "A54                             1574 non-null float64\n",
      "A55                             1574 non-null float64\n",
      "A56                             1574 non-null float64\n",
      "A57                             1574 non-null float64\n",
      "A58                             1574 non-null float64\n",
      "A59                             1574 non-null float64\n",
      "A60                             1574 non-null int64\n",
      "A61                             1574 non-null int64\n",
      "A62                             1574 non-null float64\n",
      "A67                             1574 non-null float64\n",
      "A68                             1574 non-null float64\n",
      "A69                             1574 non-null float64\n",
      "agecatage                       1574 non-null int64\n",
      "maritalstatusa1                 1574 non-null int64\n",
      "Regiona61                       1574 non-null int64\n",
      "Sales_rest                      1574 non-null int64\n",
      "Sales_rest_category             1574 non-null int64\n",
      "Sales_rest_category_Negative    1574 non-null int64\n",
      "Sales_rest_category_low         1574 non-null int64\n",
      "Sales_rest_category_high        1574 non-null int64\n",
      "SalesHighSupport                1574 non-null int64\n",
      "A55_a                           1574 non-null float64\n",
      "A56_a                           1574 non-null float64\n",
      "A57_a                           1574 non-null float64\n",
      "A58_a                           1574 non-null float64\n",
      "A38_valid                       1574 non-null float64\n",
      "bb                              1574 non-null int64\n",
      "A38_rec                         1574 non-null int64\n",
      "A39_rec                         1574 non-null int64\n",
      "A40_rec                         1574 non-null int64\n",
      "A55_rec                         1574 non-null int64\n",
      "A56_rec                         1574 non-null int64\n",
      "A57_rec                         1574 non-null int64\n",
      "A58_rec                         1574 non-null int64\n",
      "A59_rec                         1574 non-null int64\n",
      "II_STATIA                       1574 non-null float64\n",
      "filter_$                        1574 non-null int64\n",
      "attit2                          1574 non-null int64\n",
      "support0_8                      1574 non-null float64\n",
      "age_13_25                       1574 non-null float64\n",
      "age_26_35                       1574 non-null float64\n",
      "age_36_45                       1574 non-null float64\n",
      "age_46_55                       1574 non-null float64\n",
      "age_56_70                       1574 non-null float64\n",
      "female                          1574 non-null float64\n",
      "male                            1574 non-null float64\n",
      "Primary_or_Secondary            1574 non-null float64\n",
      "Middle_college                  1574 non-null float64\n",
      "University                      1574 non-null float64\n",
      "Low                             1574 non-null float64\n",
      "Middle                          1574 non-null float64\n",
      "High                            1574 non-null float64\n",
      "Not_applicable                  1574 non-null float64\n",
      "Smoke_daily                     1574 non-null float64\n",
      "Smoke_less_then_daily           1574 non-null float64\n",
      "Smoked_in_the_past              1574 non-null float64\n",
      "Never_smoker                    1574 non-null float64\n",
      "a62_income                      1574 non-null float64\n",
      "a4_smoking_status               1574 non-null float64\n",
      "dtypes: float64(61), int64(34)\n",
      "memory usage: 1.2 MB\n"
     ]
    }
   ],
   "source": [
    "dfx_imputed = impute_missing(dfx,variable_type)\n",
    "dfx_imputed.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_binary_and_category(x,variable_type):\n",
    "    \"\"\"\n",
    "    convert binary to +-1, category to one hot; remain continuous.\n",
    "    \"\"\"    \n",
    "    onehot_encoder = OneHotEncoder(sparse=False,categories='auto')\n",
    "\n",
    "    # create 2 initial columns\n",
    "    x_new = np.zeros((x.shape[0],2))\n",
    "\n",
    "    for i,i_type in enumerate(variable_type):\n",
    "        if i_type == 1: # binary\n",
    "            unique_value = np.unique(x[:,i])\n",
    "            x1 = np.array([-1. if value == unique_value[0] else 1. for value in x[:,i]])        \n",
    "            x_new = np.hstack((x_new,x1[:,np.newaxis]))\n",
    "\n",
    "        elif i_type == 2: # category\n",
    "            x1 = onehot_encoder.fit_transform(x[:,i].reshape(-1,1))\n",
    "            x_new = np.hstack((x_new,x1))\n",
    "            \n",
    "        else: # continuous      \n",
    "            x_new = np.hstack((x_new,x[:,i][:,np.newaxis]))      \n",
    "\n",
    "    # drop the 2 initial column\n",
    "    x_new = x_new[:,2:]\n",
    "    \n",
    "    return x_new.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1574, 132)\n",
      "[[35.  1.  1. ...  0.  0.  0.]\n",
      " [34. -1.  4. ...  0.  0.  0.]\n",
      " [37.  1.  3. ...  0.  0.  0.]\n",
      " ...\n",
      " [28. -1.  4. ...  0.  0.  1.]\n",
      " [29. -1.  2. ...  1.  0.  0.]\n",
      " [47.  1.  1. ...  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# convert x\n",
    "x = np.array(dfx_imputed)\n",
    "x_new = convert_binary_and_category(x,variable_type)\n",
    "\n",
    "print(x_new.shape)\n",
    "print(x_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([852, 722]))\n"
     ]
    }
   ],
   "source": [
    "y = np.array(dfy)\n",
    "#print(np.unique(y,return_counts=True))\n",
    "\n",
    "# convert taget to 0 and 1\n",
    "y_new = y\n",
    "#y_new = np.ones(y.shape[0])\n",
    "#y_new[y =='No'] = 0\n",
    "\n",
    "print(np.unique(y_new,return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine X and y and save to a file\n",
    "xy_new = np.hstack((x_new,y_new[:,np.newaxis]))\n",
    "np.savetxt('data_processed.dat',xy_new,fmt='%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
