{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing\n",
    "\n",
    "This Jupyter Noterbook helps us to convert binary attribute(s) to +/-1, categorical attributes(s) to onehot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the data which were cleaned from the `data cleaning` step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1163, 60)\n",
      "[['165.0' '13.75' '287.0' ... '1.0' '12.0' '1.0']\n",
      " ['172.0' '14.33333333' '368.0' ... '0.0' '9.0' '1.0']\n",
      " ['160.0' '13.33333333' '266.0' ... '0.0' '6.0' '1.0']\n",
      " ...\n",
      " ['119.0' '9.916666667000001' '337.0' ... '4.0' '9.0' '0.0']\n",
      " ['112.0' '9.333333332999999' '511.0' ... '5.0' '15.0' '0.0']\n",
      " ['108.0' '9.0' '495.0' ... '4.0' '12.0' '0.0']]\n"
     ]
    }
   ],
   "source": [
    "Xy = np.loadtxt('language_cleaned.dat', dtype = 'str')\n",
    "\n",
    "print(Xy.shape)\n",
    "print(Xy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find number of unique value for each column, to have an idea about which variables are continuous, which variables are binary, category. It depends on data, however it is likely that nu = 2 --> binary; nu = 3 or 4: --> category, n > 4: continuous. Of course, we have to see data in detail as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of uniques of each variable:\n",
      "[ 129  129  611  133   99  396  643  578   51   13   59   48   52 1160\n",
      " 1161 1162 1158 1161 1156  970  970   13   13  643  643  133  133  664\n",
      " 1095  970  978   93  592  628   81   56   16   17   30  103   12   43\n",
      "  129   44   58   60   51   11   17   13 1161   16   24   25   32    3\n",
      "    3   22   61]\n"
     ]
    }
   ],
   "source": [
    "X = Xy[:,:-1]\n",
    "l,n = X.shape\n",
    "nu = np.array([len(np.unique(X[:,i])) for i in range(n)])\n",
    "print('number of uniques of each variable:')\n",
    "print(nu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i_binary: []\n",
      "i_category: [55, 56]\n"
     ]
    }
   ],
   "source": [
    "i_binary = []\n",
    "i_category = []\n",
    "i_continuous = []\n",
    "for i in range(X.shape[1]):\n",
    "    nu = np.unique(X[:,i])\n",
    "    if len(nu) == 2: # binary \n",
    "        i_binary.append(i)\n",
    "    elif len(nu) < 5:\n",
    "        i_category.append(i)\n",
    "    else:\n",
    "        i_continuous.append(i)\n",
    "        \n",
    "print('i_binary:',i_binary)\n",
    "print('i_category:',i_category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then define variable type, 1: continuous, 2: binary, 3: category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 3. 3. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "variable_type  = np.ones(n) # continuous\n",
    "variable_type[i_binary] = 2 # binary\n",
    "variable_type[i_category] = 3 # categorical\n",
    "\n",
    "print(variable_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then check if categorical variables have enough values in each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['0.0', '1.0', '2.0'], dtype='<U22'), array([1123,   32,    8]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(X[:,55],return_counts=True)\n",
    "np.unique(X[:,56],return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then drop both if it's clear that there is a significant majority of a particular value in the category compared to others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['165.0', '13.75', '287.0', ..., '7.0', '1.0', '12.0'],\n",
       "       ['172.0', '14.33333333', '368.0', ..., '5.0', '0.0', '9.0'],\n",
       "       ['160.0', '13.33333333', '266.0', ..., '5.0', '0.0', '6.0'],\n",
       "       ...,\n",
       "       ['119.0', '9.916666667000001', '337.0', ..., '5.0', '4.0', '9.0'],\n",
       "       ['112.0', '9.333333332999999', '511.0', ..., '9.0', '5.0', '15.0'],\n",
       "       ['108.0', '9.0', '495.0', ..., '7.0', '4.0', '12.0']], dtype='<U22')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#np.delete(X, np.s_[55:57], axis=1)\n",
    "np.delete(X, [55,56], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now convert category to onehot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_binary_and_category(x,variable_type):\n",
    "    \"\"\"\n",
    "    convert binary to +-1, category to one hot; remain continuous.\n",
    "    \"\"\"\n",
    "    \n",
    "    onehot_encoder = OneHotEncoder(sparse=False,categories='auto')\n",
    "\n",
    "    # create 2 initial columns\n",
    "    x_new = np.zeros((x.shape[0],2))\n",
    "\n",
    "    for i,i_type in enumerate(variable_type):\n",
    "        if i_type == 1: # continuous\n",
    "            x_new = np.hstack((x_new,x[:,i][:,np.newaxis]))\n",
    "        elif i_type == 2: # binary\n",
    "            unique_value = np.unique(x[:,i])\n",
    "            x1 = np.array([-1. if value == unique_value[0] else 1. for value in x[:,i]])        \n",
    "            x_new = np.hstack((x_new,x1[:,np.newaxis]))\n",
    "        else: # category      \n",
    "            x1 = onehot_encoder.fit_transform(x[:,i].reshape(-1,1))\n",
    "            x_new = np.hstack((x_new,x1))        \n",
    "\n",
    "    # drop the 2 initial column\n",
    "    x_new = x_new[:,2:]\n",
    "    \n",
    "    return x_new.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1163, 63)\n",
      "[[165.          13.75       287.         ...   0.           1.\n",
      "   12.        ]\n",
      " [172.          14.33333333 368.         ...   0.           0.\n",
      "    9.        ]\n",
      " [160.          13.33333333 266.         ...   0.           0.\n",
      "    6.        ]\n",
      " ...\n",
      " [119.           9.91666667 337.         ...   0.           4.\n",
      "    9.        ]\n",
      " [112.           9.33333333 511.         ...   0.           5.\n",
      "   15.        ]\n",
      " [108.           9.         495.         ...   0.           4.\n",
      "   12.        ]]\n"
     ]
    }
   ],
   "source": [
    "# convert X\n",
    "X_new = convert_binary_and_category(X,variable_type)\n",
    "\n",
    "print(X_new.shape)\n",
    "print(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0., 1.]), array([896, 267]))\n"
     ]
    }
   ],
   "source": [
    "## target\n",
    "y = Xy[:,-1].astype(float)\n",
    "\n",
    "print(np.unique(y,return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0., 1.]), array([896, 267]))\n"
     ]
    }
   ],
   "source": [
    "y_new = y\n",
    "\n",
    "\n",
    "print(np.unique(y_new,return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine X and y\n",
    "Xy_new = np.hstack((X_new,y_new[:,np.newaxis]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('language_processed.dat',Xy_new,fmt='%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
