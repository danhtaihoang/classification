{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expectation Reflection + Least Absolute Deviations\n",
    "\n",
    "In the following, we demonstrate how to apply Least Absolute Deviations (LAD) for classification task such as medical diagnosis.\n",
    "\n",
    "We import the necessary packages to the Jupyter notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,precision_score,\\\n",
    "recall_score,roc_curve,auc\n",
    "\n",
    "from scipy import linalg\n",
    "from scipy.special import erf as sperf\n",
    "\n",
    "import expectation_reflection as ER\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from function import split_train_test,make_data_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, the processed data are imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1paradox' '2peptide' '3stigma' '4nki' '5mental' '6smoking' '7anemia'\n",
      " '8language' '9coag' '10tazamia' '11hepato' '12heat' '13ef' '14cervix'\n",
      " '15heart' '16liver' '17nwosu' '18school' '19ibs' '21survival' '101kidney'\n",
      " '102breast_cancer' '103diabetes_niddk' '104diabetic_retinopathy'\n",
      " '29parkinson' '30paradox2' '31renal' '33svr' '35pcos' '36probiotic']\n"
     ]
    }
   ],
   "source": [
    "data_list = np.loadtxt('data_list.txt',dtype='str')\n",
    "#data_list = ['29parkinson','30paradox2','31renal','32patientcare','33svr','34newt','35pcos']\n",
    "print(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_id):    \n",
    "    data_name = data_list[data_id]\n",
    "    print('data_name:',data_name)\n",
    "    Xy = np.loadtxt('../data/%s/data_processed.dat'%data_name) \n",
    "    X = Xy[:,:-1]\n",
    "    y = Xy[:,-1]\n",
    "\n",
    "    #print(np.unique(y,return_counts=True))\n",
    "\n",
    "    X,y = make_data_balance(X,y)\n",
    "\n",
    "    print(np.unique(y,return_counts=True))\n",
    "\n",
    "    X, y = shuffle(X, y, random_state=1)\n",
    "\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.5,random_state = 1)\n",
    "    \n",
    "    sc = MinMaxScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    \n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_LAD(x, y, regu=0.1,tol=1e-6, max_iter=1000):\n",
    "## 2019.12.26: Jungmin's code    \n",
    "    weights_limit = sperf(1e-10)*1e10\n",
    "    \n",
    "    s_sample, s_pred = x.shape\n",
    "    s_sample, s_target = y.shape\n",
    "    \n",
    "    mu = np.zeros(x.shape[1])\n",
    "\n",
    "    w_sol = 0.0*(np.random.rand(s_pred,s_target) - 0.5)\n",
    "    b_sol = np.random.rand(1,s_target) - 0.5\n",
    "\n",
    "#     print(weights.shape)\n",
    "    for index in range(s_target):\n",
    "        error, old_error = np.inf, 0\n",
    "        weights = np.ones((s_sample, 1))\n",
    "        cov = np.cov(np.hstack((x,y[:,index][:,None])), rowvar=False, \\\n",
    "                     ddof=0, aweights=weights.reshape(s_sample))\n",
    "        cov_xx, cov_xy = cov[:s_pred,:s_pred],cov[:s_pred,s_pred:(s_pred+1)]\n",
    "\n",
    "#         print(cov.shape, cov_xx.shape, cov_xy.shape)\n",
    "        counter = 0\n",
    "        while np.abs(error-old_error) > tol and counter < max_iter:\n",
    "            counter += 1\n",
    "            old_error = np.mean(np.abs(b_sol[0,index] + x.dot(w_sol[:,index]) - y[:,index]))\n",
    "#             old_error = np.mean(np.abs(b_sol[0,index] + x_test.dot(w_sol[:,index]) - y_test[:,index]))\n",
    "#             print(w_sol[:,index].shape, npl.solve(cov_xx, cov_xy).reshape(s_pred).shape)\n",
    "\n",
    "            # 2019.12.26: Tai - added regularization\n",
    "            sigma_w = np.std(w_sol[:,index])\n",
    "                \n",
    "            w_eq_0 = np.abs(w_sol[:,index]) < 1e-10\n",
    "            mu[w_eq_0] = 2./np.sqrt(np.pi)\n",
    "        \n",
    "            mu[~w_eq_0] = sigma_w*sperf(w_sol[:,index][~w_eq_0]/sigma_w)/w_sol[:,index][~w_eq_0]\n",
    "                                                        \n",
    "            w_sol[:,index] = np.linalg.solve(cov_xx + regu*np.diag(mu),cov_xy).reshape(s_pred)\n",
    "        \n",
    "            b_sol[0,index] = np.mean(y[:,index]-x.dot(w_sol[:,index]))\n",
    "            weights = (b_sol[0,index] + x.dot(w_sol[:,index]) - y[:,index])\n",
    "            sigma = np.std(weights)\n",
    "            error = np.mean(np.abs(weights))\n",
    "#             error = np.mean(np.abs(b_sol[0,index] + x_test.dot(w_sol[:,index]) - y_test[:,index]))\n",
    "            weights_eq_0 = np.abs(weights) < 1e-10\n",
    "            weights[weights_eq_0] = weights_limit\n",
    "            weights[~weights_eq_0] = sigma*sperf(weights[~weights_eq_0]/sigma)/weights[~weights_eq_0]\n",
    "            \n",
    "            #weights = sigma*sperf(weights/sigma)/weights            \n",
    "            cov = np.cov(np.hstack((x,y[:,index][:,None])), rowvar=False, \\\n",
    "                         ddof=0, aweights=weights.reshape(s_sample))\n",
    "            cov_xx, cov_xy = cov[:s_pred,:s_pred],cov[:s_pred,s_pred:(s_pred+1)]\n",
    "#             print(old_error,error)\n",
    "    #return b_sol,w_sol \n",
    "    return b_sol[0][0],w_sol[:,0] # for only one target case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_LAD(x,y,niter_max,l2):      \n",
    "    # convert 0, 1 to -1, 1\n",
    "    y1 = 2*y - 1.\n",
    "   \n",
    "    #print(niter_max)    \n",
    "    n = x.shape[1]\n",
    "    \n",
    "    x_av = np.mean(x,axis=0)\n",
    "    dx = x - x_av\n",
    "    c = np.cov(dx,rowvar=False,bias=True)\n",
    "\n",
    "    # 2019.07.16:  \n",
    "    c += l2*np.identity(n) / (2*len(y))\n",
    "    c_inv = linalg.pinvh(c)\n",
    "\n",
    "    # initial values\n",
    "    h0 = 0.\n",
    "    w = np.random.normal(0.0,1./np.sqrt(n),size=(n))\n",
    "    \n",
    "    cost = np.full(niter_max,100.)\n",
    "    for iloop in range(niter_max):\n",
    "        h = h0 + x.dot(w)\n",
    "        y1_model = np.tanh(h/2.)    \n",
    "\n",
    "        # stopping criterion\n",
    "        p = 1/(1+np.exp(-h))                \n",
    "        cost[iloop] = ((p-y)**2).mean()\n",
    "\n",
    "        #h_test = h0 + x_test.dot(w)\n",
    "        #p_test = 1/(1+np.exp(-h_test))\n",
    "        #cost[iloop] = ((p_test-y_test)**2).mean()\n",
    "\n",
    "        if iloop>0 and cost[iloop] >= cost[iloop-1]: break\n",
    "\n",
    "        # update local field\n",
    "        t = h!=0    \n",
    "        h[t] *= y1[t]/y1_model[t]\n",
    "        h[~t] = 2*y1[~t]\n",
    "\n",
    "        # find w from h    \n",
    "        #h_av = h.mean()\n",
    "        #dh = h - h_av \n",
    "        #dhdx = dh[:,np.newaxis]*dx[:,:]\n",
    "        #dhdx_av = dhdx.mean(axis=0)\n",
    "        #w = c_inv.dot(dhdx_av)\n",
    "        #h0 = h_av - x_av.dot(w)\n",
    "\n",
    "        # 2019.12.26: \n",
    "        h0,w = infer_LAD(x,h[:,np.newaxis],l2)\n",
    "\n",
    "    return h0,w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_performance(X_train,X_test,y_train,y_test):\n",
    "\n",
    "    n = X_train.shape[1]\n",
    "\n",
    "    l2 = [0.0001,0.001,0.01,0.1,1.,10.,100.]\n",
    "    #l2 = [0.0001,0.001,0.01,0.1,1.,10.]\n",
    "    nl2 = len(l2)\n",
    "\n",
    "    # cross validation \n",
    "    kf = 4   \n",
    "    kfold = KFold(n_splits=kf,shuffle=False,random_state=1)\n",
    "\n",
    "    h01 = np.zeros(kf)\n",
    "    w1 = np.zeros((kf,n))\n",
    "    cost1 = np.zeros(kf)\n",
    "\n",
    "    h0 = np.zeros(nl2)\n",
    "    w = np.zeros((nl2,n))\n",
    "    cost = np.zeros(nl2)            \n",
    "    for il2 in range(len(l2)):            \n",
    "        for i,(train_index,val_index) in enumerate(kfold.split(y_train)):\n",
    "            X_train1, X_val = X_train[train_index], X_train[val_index]\n",
    "            y_train1, y_val = y_train[train_index], y_train[val_index]\n",
    "            #h01[i],w1[i,:] = ER.fit(X_train1,y_train1,niter_max=100,l2=l2[il2])\n",
    "            #h01[i],w1[i,:] = ER.fit_LAD(X_train1,y_train1,niter_max=100,l2=l2[il2])\n",
    "            h01[i],w1[i,:] = fit_LAD(X_train1,y_train1,niter_max=100,l2=l2[il2])\n",
    "\n",
    "            y_val_pred,p_val_pred = ER.predict(X_val,h01[i],w1[i])\n",
    "            cost1[i] = ((p_val_pred - y_val)**2).mean()\n",
    "\n",
    "        h0[il2] = h01.mean(axis=0)\n",
    "        w[il2,:] = w1.mean(axis=0)\n",
    "        cost[il2] = cost1.mean()\n",
    "\n",
    "    # optimal value of l2:\n",
    "    il2_opt = np.argmin(cost)\n",
    "    print('optimal l2:',l2[il2_opt])\n",
    "\n",
    "    # performance:\n",
    "    y_test_pred,p_test_pred = ER.predict(X_test,h0[il2_opt],w[il2_opt,:])\n",
    "\n",
    "    fp,tp,thresholds = roc_curve(y_test, p_test_pred, drop_intermediate=False)\n",
    "\n",
    "    roc_auc = auc(fp,tp)\n",
    "    #print('AUC:', roc_auc)\n",
    "\n",
    "    acc = accuracy_score(y_test,y_test_pred)\n",
    "    #print('Accuracy:', acc)\n",
    "\n",
    "    precision = precision_score(y_test,y_test_pred)\n",
    "    #print('Precision:',precision)\n",
    "\n",
    "    recall = recall_score(y_test,y_test_pred)\n",
    "    #print('Recall:',recall)\n",
    "\n",
    "    return acc,roc_auc,precision,recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_name: 1paradox\n",
      "(array([0., 1.]), array([60, 60]))\n",
      "optimal l2: 0.001\n",
      "0 0.8166666666666667 0.8736780258519389\n",
      "data_name: 2peptide\n",
      "(array([0., 1.]), array([23, 23]))\n",
      "optimal l2: 0.0001\n",
      "1 0.9130434782608695 1.0\n",
      "data_name: 3stigma\n",
      "(array([0., 1.]), array([2725, 2725]))\n",
      "optimal l2: 0.001\n",
      "2 0.9922935779816514 0.9926971007107359\n",
      "data_name: 4nki\n",
      "(array([0., 1.]), array([77, 77]))\n",
      "optimal l2: 1.0\n",
      "3 0.8311688311688312 0.8891891891891891\n",
      "data_name: 5mental\n",
      "(array([0., 1.]), array([147, 147]))\n",
      "optimal l2: 1.0\n",
      "4 0.6530612244897959 0.6975881261595548\n",
      "data_name: 6smoking\n",
      "(array([0., 1.]), array([722, 722]))\n",
      "optimal l2: 0.001\n",
      "5 1.0 1.0\n",
      "data_name: 7anemia\n",
      "(array([0., 1.]), array([43, 43]))\n",
      "optimal l2: 0.001\n",
      "6 0.6744186046511628 0.8031674208144797\n",
      "data_name: 8language\n",
      "(array([0., 1.]), array([267, 267]))\n",
      "optimal l2: 0.01\n",
      "7 0.7640449438202247 0.828972487366648\n",
      "data_name: 9coag\n",
      "(array([0., 1.]), array([504, 504]))\n",
      "optimal l2: 0.001\n",
      "8 0.5972222222222222 0.6531715388858247\n",
      "data_name: 10tazamia\n",
      "(array([0., 1.]), array([124, 124]))\n",
      "optimal l2: 0.1\n",
      "9 0.75 0.8735177865612649\n",
      "data_name: 11hepato\n",
      "(array([0., 1.]), array([63, 63]))\n",
      "optimal l2: 0.1\n",
      "10 0.5873015873015873 0.6955645161290324\n",
      "data_name: 12heat\n",
      "(array([0., 1.]), array([83, 83]))\n",
      "optimal l2: 1.0\n",
      "11 0.6867469879518072 0.7096399535423926\n",
      "data_name: 13ef\n",
      "(array([0., 1.]), array([93, 93]))\n",
      "optimal l2: 0.0001\n",
      "12 1.0 1.0\n",
      "data_name: 14cervix\n",
      "(array([0., 1.]), array([24, 24]))\n",
      "optimal l2: 0.1\n",
      "13 1.0 1.0\n",
      "data_name: 15heart\n",
      "(array([0., 1.]), array([138, 138]))\n",
      "optimal l2: 0.1\n",
      "14 0.7971014492753623 0.902845100105374\n",
      "data_name: 16liver\n",
      "(array([0., 1.]), array([167, 167]))\n",
      "optimal l2: 0.001\n",
      "15 0.6826347305389222 0.7492753623188406\n",
      "data_name: 17nwosu\n",
      "(array([0., 1.]), array([59, 59]))\n",
      "optimal l2: 0.0001\n",
      "16 1.0 1.0\n",
      "data_name: 18school\n",
      "(array([0., 1.]), array([68, 68]))\n",
      "optimal l2: 1.0\n",
      "17 0.8529411764705882 0.8637152777777778\n",
      "data_name: 19ibs\n",
      "(array([0., 1.]), array([33, 33]))\n",
      "optimal l2: 0.1\n",
      "18 0.6666666666666666 0.9285714285714286\n",
      "data_name: 21survival\n",
      "(array([0., 1.]), array([123, 123]))\n",
      "optimal l2: 0.1\n",
      "19 0.8130081300813008 0.9139300847457626\n",
      "data_name: 101kidney\n",
      "(array([0., 1.]), array([149, 149]))\n",
      "optimal l2: 0.001\n",
      "20 0.9932885906040269 1.0\n",
      "data_name: 102breast_cancer\n",
      "(array([0., 1.]), array([212, 212]))\n",
      "optimal l2: 0.001\n",
      "21 0.9481132075471698 0.991003830052552\n",
      "data_name: 103diabetes_niddk\n",
      "(array([0., 1.]), array([252, 252]))\n",
      "optimal l2: 0.01\n",
      "22 0.7182539682539683 0.8189170405004107\n",
      "data_name: 104diabetic_retinopathy\n",
      "(array([0., 1.]), array([536, 536]))\n",
      "optimal l2: 0.0001\n",
      "23 0.7350746268656716 0.8118708491708784\n",
      "data_name: 29parkinson\n",
      "(array([0., 1.]), array([48, 48]))\n",
      "optimal l2: 0.01\n",
      "24 0.6666666666666666 0.7391304347826086\n",
      "data_name: 30paradox2\n",
      "(array([0., 1.]), array([52, 52]))\n",
      "optimal l2: 0.001\n",
      "25 1.0 1.0\n",
      "data_name: 31renal\n",
      "(array([0., 1.]), array([47, 47]))\n",
      "optimal l2: 0.01\n",
      "26 0.8297872340425532 0.8963636363636365\n",
      "data_name: 33svr\n",
      "(array([0., 1.]), array([41, 41]))\n",
      "optimal l2: 0.0001\n",
      "27 0.975609756097561 0.9785714285714285\n",
      "data_name: 35pcos\n",
      "(array([0., 1.]), array([177, 177]))\n",
      "optimal l2: 0.01\n",
      "28 0.8305084745762712 0.9202319587628868\n",
      "data_name: 36probiotic\n",
      "(array([0., 1.]), array([10, 10]))\n",
      "optimal l2: 0.01\n",
      "29 0.7 0.9166666666666666\n"
     ]
    }
   ],
   "source": [
    "n_data = len(data_list)\n",
    "roc_auc = np.zeros(n_data)   ; acc = np.zeros(n_data)\n",
    "precision = np.zeros(n_data) ; recall = np.zeros(n_data)\n",
    "for data_id in range(n_data):\n",
    "    X_train,X_test,y_train,y_test = read_data(data_id)\n",
    "    acc[data_id],roc_auc[data_id],precision[data_id],recall[data_id] =\\\n",
    "            measure_performance(X_train,X_test,y_train,y_test)\n",
    "    print(data_id,acc[data_id],roc_auc[data_id]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_mean: 0.8158540934067182\n",
      "roc_mean: 0.8816093081200438\n",
      "precision: 0.8381962239057751\n",
      "recall: 0.8033483899691063\n"
     ]
    }
   ],
   "source": [
    "print('acc_mean:',acc.mean())\n",
    "print('roc_mean:',roc_auc.mean())\n",
    "\n",
    "print('precision:',precision.mean())\n",
    "print('recall:',recall.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savetxt('ER_LAD_result_30sets.dat',(roc_auc,acc,precision,recall),fmt='%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
